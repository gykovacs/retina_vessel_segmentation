{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('retina_vessel_segmentation': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d6a73522bb3712d594d20da483abbf8261279d7e80b2bfe8d6ba9eebd496c684"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Analysis of aggregated figures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import os\n",
    "\n",
    "from core import *\n",
    "\n",
    "from config import image_stats_file, figures_dir, latex_dir, xls_file, image_level_results_file, aggregated_results_file\n",
    "from config import exclude_stare_training, aggregated_threshold\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.width', 10000)\n",
    "\n",
    "data= pd.read_csv(image_stats_file)\n",
    "il_results= pd.read_csv(image_level_results_file)\n",
    "il_results.index=il_results['key']\n",
    "\n",
    "# reading the summary page\n",
    "methods= pd.read_excel(xls_file, engine='openpyxl')\n",
    "#methods= methods.iloc[:methods[methods['key'].isnull()].index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id   n_all      p       n    fov  annotator  tp  fp  tn  fn  ground_truth  width  height  img_size   test  acc  sens  spec  dice  dice_no_fp\n",
       "0  34  226542  32287  194255   True          1 NaN NaN NaN NaN           NaN    584     565    329960  False  NaN   NaN   NaN   NaN         NaN\n",
       "1  34  329960  32287  297673  False          1 NaN NaN NaN NaN           NaN    584     565    329960  False  NaN   NaN   NaN   NaN         NaN\n",
       "2  24  227726  38215  189511   True          1 NaN NaN NaN NaN           NaN    584     565    329960  False  NaN   NaN   NaN   NaN         NaN\n",
       "3  24  329960  38229  291731  False          1 NaN NaN NaN NaN           NaN    584     565    329960  False  NaN   NaN   NaN   NaN         NaN\n",
       "4  29  227309  27738  199571   True          1 NaN NaN NaN NaN           NaN    584     565    329960  False  NaN   NaN   NaN   NaN         NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>n_all</th>\n      <th>p</th>\n      <th>n</th>\n      <th>fov</th>\n      <th>annotator</th>\n      <th>tp</th>\n      <th>fp</th>\n      <th>tn</th>\n      <th>fn</th>\n      <th>ground_truth</th>\n      <th>width</th>\n      <th>height</th>\n      <th>img_size</th>\n      <th>test</th>\n      <th>acc</th>\n      <th>sens</th>\n      <th>spec</th>\n      <th>dice</th>\n      <th>dice_no_fp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34</td>\n      <td>226542</td>\n      <td>32287</td>\n      <td>194255</td>\n      <td>True</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>34</td>\n      <td>329960</td>\n      <td>32287</td>\n      <td>297673</td>\n      <td>False</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24</td>\n      <td>227726</td>\n      <td>38215</td>\n      <td>189511</td>\n      <td>True</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>24</td>\n      <td>329960</td>\n      <td>38229</td>\n      <td>291731</td>\n      <td>False</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29</td>\n      <td>227309</td>\n      <td>27738</td>\n      <td>199571</td>\n      <td>True</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         key      flag    year all_previous_processed     acc       sens    spec  digits highest_ranked second_human_observer  second_human_acc  second_human_sens  second_human_spec image_level                            short_description                operating_principles  citations explicit_fov_usage invalid_ranking        cause_of_invalid_ranking\n",
       "0  adapa2020   primary  2020.0                    yes  0.9450     0.6994  0.9811       4  thangaraj2017                    no               NaN                NaN                NaN         yes  neural network with Zernike moment features  feature extraction, classification        4.0         no mention             yes  fov, compares to thangaraj2017\n",
       "1   alom2019   primary  2019.0                    yes  0.9613     0.7661  0.9807       4       alom2019                    no               NaN                NaN                NaN          no                          deep learning u-net                       deep learning       46.0         no mention             yes       compares to azzopardi2014\n",
       "2   alom2019     U-net     NaN                    NaN  0.9531  7537.0000  0.9820       4            NaN                   NaN               NaN                NaN                NaN         NaN                                          NaN                                 NaN        NaN                NaN             NaN                             NaN\n",
       "3   alom2019  Resu-net     NaN                    NaN  0.9553     0.7726  0.9820       4            NaN                   NaN               NaN                NaN                NaN         NaN                                          NaN                                 NaN        NaN                NaN             NaN                             NaN\n",
       "4   alom2019    Ru-net     NaN                    NaN  0.9556     0.7751  0.9816       4            NaN                   NaN               NaN                NaN                NaN         NaN                                          NaN                                 NaN        NaN                NaN             NaN                             NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>flag</th>\n      <th>year</th>\n      <th>all_previous_processed</th>\n      <th>acc</th>\n      <th>sens</th>\n      <th>spec</th>\n      <th>digits</th>\n      <th>highest_ranked</th>\n      <th>second_human_observer</th>\n      <th>second_human_acc</th>\n      <th>second_human_sens</th>\n      <th>second_human_spec</th>\n      <th>image_level</th>\n      <th>short_description</th>\n      <th>operating_principles</th>\n      <th>citations</th>\n      <th>explicit_fov_usage</th>\n      <th>invalid_ranking</th>\n      <th>cause_of_invalid_ranking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>adapa2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>yes</td>\n      <td>0.9450</td>\n      <td>0.6994</td>\n      <td>0.9811</td>\n      <td>4</td>\n      <td>thangaraj2017</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>yes</td>\n      <td>neural network with Zernike moment features</td>\n      <td>feature extraction, classification</td>\n      <td>4.0</td>\n      <td>no mention</td>\n      <td>yes</td>\n      <td>fov, compares to thangaraj2017</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>alom2019</td>\n      <td>primary</td>\n      <td>2019.0</td>\n      <td>yes</td>\n      <td>0.9613</td>\n      <td>0.7661</td>\n      <td>0.9807</td>\n      <td>4</td>\n      <td>alom2019</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>no</td>\n      <td>deep learning u-net</td>\n      <td>deep learning</td>\n      <td>46.0</td>\n      <td>no mention</td>\n      <td>yes</td>\n      <td>compares to azzopardi2014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>alom2019</td>\n      <td>U-net</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.9531</td>\n      <td>7537.0000</td>\n      <td>0.9820</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>alom2019</td>\n      <td>Resu-net</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.9553</td>\n      <td>0.7726</td>\n      <td>0.9820</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>alom2019</td>\n      <td>Ru-net</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.9556</td>\n      <td>0.7751</td>\n      <td>0.9816</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "methods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_with_fov_obs1= data[(data['test'] == True) & (data['annotator'] == 1) & (data['fov'] == True)].reset_index()\n",
    "data_test_without_fov_obs1= data[(data['test'] == True) & (data['annotator'] == 1) & (data['fov'] == False)].reset_index()"
   ]
  },
  {
   "source": [
    "## The consistency analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_avg_with_fov= np.mean(data_test_with_fov_obs1['n'].values)\n",
    "n_avg_without_fov= np.mean(data_test_without_fov_obs1['n'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processing adapa2020\n",
      "solving primary acc 0.945000 sens 0.699400 spec 0.981100 eps 0.000100\n",
      "processing alom2019\n",
      "solving primary acc 0.961300 sens 0.766100 spec 0.980700 eps 0.000100\n",
      "solving U-net acc 0.953100 sens 7537.000000 spec 0.982000 eps 0.000100\n",
      "solving Resu-net acc 0.955300 sens 0.772600 spec 0.982000 eps 0.000100\n",
      "solving Ru-net acc 0.955600 sens 0.775100 spec 0.981600 eps 0.000100\n",
      "solving r2u-net-13M acc 0.955600 sens 0.779200 spec 0.981300 eps 0.000100\n",
      "processing anzalone2008\n",
      "solving primary acc 0.941800 sens 0.728600 spec 0.981000 eps 0.000100\n",
      "processing azzopardi2014\n",
      "solving primary acc 0.944200 sens 0.765500 spec 0.970400 eps 0.000100\n",
      "solving Symmetric-filter acc 0.942700 sens 0.752600 spec 0.970700 eps 0.000100\n",
      "solving Asymmetric-filter acc 0.942200 sens 0.749900 spec 0.962100 eps 0.000100\n",
      "processing barkana2017\n",
      "solving primary acc 0.950200 sens 0.722400 spec 0.984000 eps 0.000100\n",
      "solving fuzzy acc 0.938000 sens 0.723000 spec 0.970000 eps 0.001000\n",
      "solving ann acc 0.942000 sens 0.677000 spec 0.981000 eps 0.001000\n",
      "solving svm acc 0.928300 sens 0.634300 spec 0.972200 eps 0.000100\n",
      "processing brancati2018\n",
      "solving primary acc 0.949000 sens 0.782000 spec 0.976000 eps 0.001000\n",
      "solving nobal/pool acc 0.948000 sens 0.773000 spec 0.976000 eps 0.001000\n",
      "solving bal/pool acc 0.919000 sens 0.909000 spec 0.921000 eps 0.001000\n",
      "solving bal/nopool acc 0.926000 sens 0.891000 spec 0.932000 eps 0.001000\n",
      "solving Without-df acc 0.949000 sens 0.769000 spec 0.977000 eps 0.001000\n",
      "processing budai2013\n",
      "solving primary acc 0.957000 sens 0.644000 spec 0.987000 eps 0.001000\n",
      "processing chalakkal2017\n",
      "solving primary acc 0.951800 sens 0.738600 spec 0.976900 eps 0.000100\n",
      "processing cheng2014\n",
      "solving primary acc 0.947400 sens 0.725200 spec 0.979800 eps 0.000100\n",
      "solving intensity acc 0.928400 sens 0.615800 spec 0.973900 eps 0.000100\n",
      "solving gabor acc 0.935300 sens 0.672300 spec 0.973600 eps 0.000100\n",
      "solving swt acc 0.918400 sens 0.552600 spec 0.971800 eps 0.000100\n",
      "solving wld acc 0.932600 sens 0.619800 spec 0.978200 eps 0.000100\n",
      "solving vesselness acc 0.933700 sens 0.646800 spec 0.975500 eps 0.000100\n",
      "processing dai2015\n",
      "solving primary acc 0.941800 sens 0.735900 spec 0.972000 eps 0.000100\n",
      "processing dasgupta2017\n",
      "solving primary acc 0.953300 sens 0.769100 spec 0.980100 eps 0.000100\n",
      "processing dash2018\n",
      "solving primary acc 0.957000 sens 0.741000 spec 0.986000 eps 0.001000\n",
      "processing dizdaroglu2012\n",
      "solving primary acc 0.941200 sens 0.718100 spec 0.974300 eps 0.000100\n",
      "solving pcp acc 0.933900 sens 0.747300 spec 0.968700 eps 0.000100\n",
      "processing emary2014\n",
      "solving primary acc 0.939000 sens 0.721000 spec 0.971000 eps 0.001000\n",
      "processing escorcia-gutierrez2020\n",
      "solving primary acc 0.964000 sens 0.617000 spec 0.998000 eps 0.001000\n",
      "processing fan2017\n",
      "solving primary acc 0.960000 sens 0.736000 spec 0.981000 eps 0.001000\n",
      "solving without vessel skeleton extraction acc 0.960000 sens 0.688000 spec 0.986000 eps 0.001000\n",
      "processing fathi2013\n",
      "solving primary acc 0.958100 sens 0.776800 spec 0.975900 eps 0.000100\n",
      "processing fraz2012\n",
      "solving primary acc 0.943000 sens 0.715200 spec 0.976900 eps 0.000100\n",
      "solving green channel acc 0.942366 sens 0.716161 spec 0.975900 eps 0.000001\n",
      "solving I component  acc 0.939063 sens 0.691526 spec 0.975556 eps 0.000001\n",
      "solving L component acc 0.940007 sens 0.631292 spec 0.985608 eps 0.000001\n",
      "solving Luminosity channel acc 0.941797 sens 0.703580 spec 0.976932 eps 0.000001\n",
      "solving Table 5 l component acc 0.943098 sens 0.715235 spec 0.976883 eps 0.000001\n",
      "solving Table 5 I component acc 0.942814 sens 0.715577 spec 0.976465 eps 0.000001\n",
      "solving Table 5 Luminosity channel acc 0.942735 sens 0.717110 spec 0.976171 eps 0.000001\n",
      "solving Table 6 gaussian noise acc 0.930100 sens 0.774100 spec 0.953700 eps 0.000100\n",
      "solving Table 6 salt and pepper acc 0.942700 sens 0.718400 spec 0.976500 eps 0.000100\n",
      "solving Table 6 speckle acc 0.932200 sens 0.762800 spec 0.964100 eps 0.000100\n",
      "processing fraz2012b\n",
      "solving primary acc 0.948000 sens 0.740600 spec 0.980700 eps 0.000100\n",
      "solving cross training acc 0.945600 sens 0.724200 spec 0.979200 eps 0.000100\n",
      "solving reduced feature set acc 0.946800 sens 0.733600 spec 0.978900 eps 0.000100\n",
      "processing frucci2016\n",
      "solving primary acc 0.955000 sens 0.640000 spec 0.985000 eps 0.001000\n",
      "processing frucci2017\n",
      "solving primary acc 0.956000 sens 0.660000 spec 0.985000 eps 0.001000\n",
      "processing geetharamani2016\n",
      "solving primary acc 0.953600 sens 0.707900 spec 0.977800 eps 0.000100\n",
      "processing hassan2018\n",
      "solving primary acc 0.979300 sens 0.898100 spec 0.988300 eps 0.000100\n",
      "processing hu2018\n",
      "solving primary acc 0.953300 sens 0.779600 spec 0.971700 eps 0.000100\n",
      "solving base acc 0.949400 sens 0.752300 spec 0.978500 eps 0.000100\n",
      "solving improved loss function acc 0.949800 sens 0.755200 spec 0.978500 eps 0.000100\n",
      "solving multiscale acc 0.952300 sens 0.769000 spec 0.979300 eps 0.000100\n",
      "processing imani2015\n",
      "solving primary acc 0.952300 sens 0.752400 spec 0.975300 eps 0.000100\n",
      "solving gaussian noise acc 0.941700 sens 0.706100 spec 0.969300 eps 0.000100\n",
      "solving poisson noise acc 0.933800 sens 0.654500 spec 0.965100 eps 0.000100\n",
      "solving salt and pepper noise acc 0.910400 sens 0.593100 spec 0.946200 eps 0.000100\n",
      "solving without separation acc 0.950100 sens 0.688800 spec 0.980000 eps 0.000100\n",
      "processing javidi2017\n",
      "solving primary acc 0.945000 sens 0.720100 spec 0.970200 eps 0.000100\n",
      "processing jebaseeli2019\n",
      "solving primary acc 0.989800 sens 0.802700 spec 0.998000 eps 0.000100\n",
      "processing jiang2019\n",
      "solving primary acc 0.970600 sens 0.832500 spec 0.983800 eps 0.000100\n",
      "solving Table 1 no 0 acc 0.954600 sens 0.735000 spec 0.986600 eps 0.000100\n",
      "solving Table 1 no 1 acc 0.969200 sens 0.800000 spec 0.985500 eps 0.000100\n",
      "solving Table 1 no 2 acc 0.969700 sens 0.804300 spec 0.985500 eps 0.000100\n",
      "solving Table 1 no 3 acc 0.970200 sens 0.821500 spec 0.984500 eps 0.000100\n",
      "solving Table 1 no 4 acc 0.968300 sens 0.808100 spec 0.983600 eps 0.000100\n",
      "solving Table 1 no 5 acc 0.969900 sens 0.837600 spec 0.982600 eps 0.000100\n",
      "solving Table 1 no 6 acc 0.967800 sens 0.823400 spec 0.981600 eps 0.000100\n",
      "solving Table 1 no 7 acc 0.970400 sens 0.820600 spec 0.984800 eps 0.000100\n",
      "processing kaur2017\n",
      "solving primary acc 0.948000 sens 0.873000 spec 0.986900 eps 0.000100\n",
      "processing khan2016\n",
      "solving primary acc 0.950100 sens 0.737300 spec 0.967000 eps 0.000100\n",
      "processing kovacs2016\n",
      "solving primary acc 0.949400 sens 0.745000 spec 0.979300 eps 0.000100\n",
      "solving step3 acc 0.949100 sens 0.734400 spec 0.980400 eps 0.000100\n",
      "processing kumar2016\n",
      "solving primary acc 0.962600 sens 0.700600 spec 0.987100 eps 0.000100\n",
      "processing li2016\n",
      "solving primary acc 0.952700 sens 0.756900 spec 0.981600 eps 0.000100\n",
      "solving trained on CHASE_DB1 acc 0.948400 sens 0.730700 spec 0.981100 eps 0.000100\n",
      "processing liskowski2016\n",
      "solving primary acc 0.953500 sens 0.781100 spec 0.980700 eps 0.000100\n",
      "solving plain acc 0.947900 sens 0.741700 spec 0.980400 eps 0.000100\n",
      "solving gcn acc 0.948700 sens 0.755000 spec 0.979200 eps 0.000100\n",
      "solving zca acc 0.948500 sens 0.781900 spec 0.974800 eps 0.000100\n",
      "solving augment acc 0.946600 sens 0.744700 spec 0.978400 eps 0.000100\n",
      "solving balanced acc 0.923000 sens 0.916000 spec 0.924100 eps 0.000100\n",
      "solving No-pool acc 0.948600 sens 0.776300 spec 0.976800 eps 0.000100\n",
      "solving Balanced-sp 3 acc 0.950700 sens 0.084600 spec 0.967300 eps 0.000100\n",
      "solving No-pool-sp 3 acc 0.951900 sens 0.802000 spec 0.975700 eps 0.000100\n",
      "solving Balanced-sp 5 acc 0.953000 sens 0.814900 spec 0.974900 eps 0.000100\n",
      "solving Balanced-sp 7 acc 0.950300 sens 0.799600 spec 0.974000 eps 0.000100\n",
      "solving No-pool-sp 7 acc 0.951800 sens 0.775000 spec 0.979500 eps 0.000100\n",
      "processing lupascu2010\n",
      "solving primary acc 0.959700 sens 0.672800 spec 0.987400 eps 0.000100\n",
      "processing mapayi2015\n",
      "solving primary acc 0.951100 sens 0.731300 spec 0.972400 eps 0.000100\n",
      "solving min range gray acc 0.948800 sens 0.739700 spec 0.969100 eps 0.000100\n",
      "solving mean range gray acc 0.950300 sens 0.737500 spec 0.970900 eps 0.000100\n",
      "solving min range green acc 0.944900 sens 0.765000 spec 0.962300 eps 0.000100\n",
      "solving max range green acc 0.947700 sens 0.756000 spec 0.966300 eps 0.000100\n",
      "solving mean range green acc 0.946100 sens 0.763200 spec 0.963400 eps 0.000100\n",
      "processing marin2011\n",
      "solving primary acc 0.945200 sens 0.706700 spec 0.980100 eps 0.000100\n",
      "processing melinscak2015\n",
      "solving primary acc 0.946600 sens 0.727600 spec 0.978500 eps 0.000100\n",
      "processing memari2017\n",
      "solving primary acc 0.972200 sens 0.872600 spec 0.988400 eps 0.000100\n",
      "solving trained on CHASE_DB1 acc 0.960800 sens 0.848800 spec 0.994900 eps 0.000100\n",
      "processing mendonca2006\n",
      "solving primary acc 0.946300 sens 0.731500 spec 0.978100 eps 0.000100\n",
      "solving gray channel acc 0.945200 sens 0.734400 spec 0.976400 eps 0.000100\n",
      "processing meng2015\n",
      "solving primary acc 0.952900 sens 0.748900 spec 0.981800 eps 0.000100\n",
      "processing miri2011\n",
      "solving primary acc 0.945800 sens 0.735200 spec 0.979500 eps 0.000100\n",
      "processing mo2017\n",
      "solving primary acc 0.952100 sens 0.776000 spec 0.977900 eps 0.000100\n",
      "solving trained on CHASE_DB1 acc 0.946000 sens 0.731500 spec 0.977800 eps 0.000100\n",
      "processing moghimirad2012\n",
      "solving primary acc 0.965900 sens 0.785200 spec 0.993500 eps 0.000100\n",
      "processing nazari2013\n",
      "solving primary acc 0.948100 sens 0.711200 spec 0.971600 eps 0.000100\n",
      "solving green channel acc 0.932500 sens 0.660100 spec 0.959600 eps 0.000100\n",
      "processing ngo2017\n",
      "solving primary acc 0.953300 sens 0.746400 spec 0.983600 eps 0.000100\n",
      "processing noh2019\n",
      "solving primary acc 0.956900 sens 0.835400 spec 0.974600 eps 0.000100\n",
      "processing odstrcilik2013\n",
      "solving primary acc 0.934000 sens 0.706000 spec 0.969300 eps 0.000100\n",
      "processing palanivel2020\n",
      "solving primary acc 0.948000 sens 0.737500 spec 0.978800 eps 0.000100\n",
      "solving Table 1 sum acc 0.943700 sens 0.675700 spec 0.982800 eps 0.000100\n",
      "solving Table 1 max acc 0.947100 sens 0.723200 spec 0.979800 eps 0.000100\n",
      "solving Table 2 max acc 0.947300 sens 0.747200 spec 0.976500 eps 0.000100\n",
      "processing pan2019\n",
      "solving primary acc 0.965000 sens 0.815000 spec 0.980800 eps 0.000100\n",
      "processing panda2016\n",
      "solving primary acc 0.953900 sens 0.732800 spec 0.975200 eps 0.000100\n",
      "solving Type 1 clustering acc 0.935300 sens 0.703800 spec 0.958200 eps 0.000100\n",
      "solving Type 1 svm acc 0.922900 sens 0.714600 spec 0.944300 eps 0.000100\n",
      "solving type II svm acc 0.952700 sens 0.733700 spec 0.973800 eps 0.000100\n",
      "processing pandey2016\n",
      "solving primary acc 0.962300 sens 0.810600 spec 0.976100 eps 0.000100\n",
      "processing park2020\n",
      "solving primary acc 0.970600 sens 0.834600 spec 0.983600 eps 0.000100\n",
      "processing rahebi2014\n",
      "solving primary acc 0.946100 sens 0.736500 spec 0.970700 eps 0.000100\n",
      "processing rezaee2017\n",
      "solving primary acc 0.946300 sens 0.718900 spec 0.979300 eps 0.000100\n",
      "processing ricci2007\n",
      "solving primary acc 0.959500 sens 0.728300 spec 0.983200 eps 0.000100\n",
      "processing roychowdhury2015\n",
      "solving primary acc 0.949400 sens 0.739500 spec 0.978200 eps 0.000100\n",
      "processing salazar-gonzalez2014\n",
      "solving primary acc 0.941200 sens 0.751200 spec 0.968400 eps 0.000100\n",
      "processing saleh2011\n",
      "solving primary acc 0.963000 sens 0.842300 spec 0.965800 eps 0.000100\n",
      "solving gray channel acc 0.955400 sens 0.830300 spec 0.969200 eps 0.000100\n",
      "processing samuel2019\n",
      "solving primary acc 0.960900 sens 0.828200 spec 0.973800 eps 0.000100\n",
      "solving Table 4 row 1 1  acc 0.954700 sens 0.847400 spec 0.965200 eps 0.000100\n",
      "solving Table 4 row 1 2 acc 0.947200 sens 0.905800 spec 0.951400 eps 0.000100\n",
      "solving Table 4 row 2 1 acc 0.956000 sens 0.842800 spec 0.967700 eps 0.000100\n",
      "processing saroj2020\n",
      "solving primary acc 0.954400 sens 0.730700 spec 0.976100 eps 0.000100\n",
      "processing shah2017\n",
      "solving primary acc 0.947900 sens 0.720500 spec 0.981400 eps 0.000100\n",
      "processing shukla2020\n",
      "solving primary acc 0.947600 sens 0.701500 spec 0.983600 eps 0.000100\n",
      "processing singh2016\n",
      "solving primary acc 0.952200 sens 0.759400 spec 0.970800 eps 0.000100\n",
      "processing singh2017\n",
      "solving primary acc 0.951300 sens 0.717100 spec 0.973900 eps 0.000100\n",
      "processing song2017\n",
      "solving primary acc 0.949900 sens 0.750100 spec 0.979500 eps 0.000100\n",
      "processing soomro2017\n",
      "solving primary acc 0.943200 sens 0.752300 spec 0.976000 eps 0.000100\n",
      "processing soomro2018\n",
      "solving primary acc 0.953400 sens 0.759200 spec 0.976300 eps 0.000100\n",
      "solving T=4 acc 0.940100 sens 0.747900 spec 0.968800 eps 0.000100\n",
      "solving T=4.3 acc 0.948900 sens 0.748100 spec 0.961200 eps 0.000100\n",
      "solving T=4.7 acc 0.944200 sens 0.749500 spec 0.970500 eps 0.000100\n",
      "processing soomro2019\n",
      "solving primary acc 0.956000 sens 0.870000 spec 0.985000 eps 0.001000\n",
      "processing sreejini2015\n",
      "solving primary acc 0.963300 sens 0.713200 spec 0.986600 eps 0.000100\n",
      "processing staal2004\n",
      "solving primary acc 0.944100 sens 0.775000 spec 0.972500 eps 0.000100\n",
      "processing strisciuglio2015\n",
      "solving primary acc 0.944200 sens 0.765500 spec 0.970400 eps 0.000100\n",
      "processing strisciuglio2016\n",
      "solving primary acc 0.945400 sens 0.777700 spec 0.970200 eps 0.000100\n",
      "solving Table 1 row 2 acc 0.943700 sens 0.790100 spec 0.967500 eps 0.000100\n",
      "solving Table 1 row 3 acc 0.945300 sens 0.775400 spec 0.970400 eps 0.000100\n",
      "solving Table 1 row 5 acc 0.943900 sens 0.785700 spec 0.967300 eps 0.000100\n",
      "solving Table 1 row 6 acc 0.945300 sens 0.773100 spec 0.970800 eps 0.000100\n",
      "processing tamim2020\n",
      "solving primary acc 0.960700 sens 0.754200 spec 0.984300 eps 0.000100\n",
      "processing tang2017\n",
      "solving primary acc 0.961100 sens 0.817400 spec 0.974700 eps 0.000100\n",
      "processing thangaraj2017\n",
      "solving primary acc 0.960600 sens 0.801400 spec 0.975300 eps 0.000100\n",
      "processing villalobos-castaldi2010\n",
      "solving primary acc 0.975900 sens 0.964900 spec 0.948000 eps 0.000100\n",
      "processing waheed2015\n",
      "solving primary acc 0.961600 sens 0.793700 spec 0.977900 eps 0.000100\n",
      "processing wang2015\n",
      "solving primary acc 0.976700 sens 0.817300 spec 0.973300 eps 0.000100\n",
      "solving cnn acc 0.954500 sens 0.642500 spec 0.947800 eps 0.000100\n",
      "solving rf-1 acc 0.976700 sens 0.817300 spec 0.973300 eps 0.000100\n",
      "solving rf-2 acc 0.973100 sens 0.789900 spec 0.969200 eps 0.000100\n",
      "solving rf.3 acc 0.969000 sens 0.757600 spec 0.964400 eps 0.000100\n",
      "solving average acc 0.971800 sens 0.778700 spec 0.967600 eps 0.000100\n",
      "solving weighted one acc 0.974200 sens 0.798300 spec 0.970400 eps 0.000100\n",
      "solving weighted two acc 0.975400 sens 0.807400 spec 0.971700 eps 0.000100\n",
      "solving median acc 0.973900 sens 0.795900 spec 0.970000 eps 0.000100\n",
      "processing wankhede2015\n",
      "solving primary acc 0.962600 sens 0.726100 spec 0.980600 eps 0.000100\n",
      "processing wu2020\n",
      "solving primary acc 0.958200 sens 0.799600 spec 0.981300 eps 0.000100\n",
      "solving Table 3 row 1 acc 0.956300 sens 0.788700 spec 0.980800 eps 0.000100\n",
      "solving Table 3 row 2 acc 0.957500 sens 0.767900 spec 0.985200 eps 0.000100\n",
      "processing xiang2014\n",
      "solving primary acc 0.961300 sens 0.753800 spec 0.982800 eps 0.000100\n",
      "processing yan2018\n",
      "solving primary acc 0.954200 sens 0.765300 spec 0.981800 eps 0.000100\n",
      "solving Pixel-wise loss acc 0.951300 sens 0.756200 spec 0.979700 eps 0.000100\n",
      "processing yang2020\n",
      "solving primary acc 0.953200 sens 0.734900 spec 0.974300 eps 0.000100\n",
      "solving LCV acc 0.934400 sens 0.798800 spec 0.947500 eps 0.000100\n",
      "solving LBF acc 0.947500 sens 0.771800 spec 0.964500 eps 0.000100\n",
      "solving AS_LBF acc 0.952200 sens 0.718100 spec 0.974700 eps 0.000100\n",
      "processing you2011\n",
      "solving primary acc 0.943400 sens 0.741000 spec 0.975100 eps 0.000100\n",
      "processing zhang2010\n",
      "solving primary acc 0.938200 sens 0.712000 spec 0.972400 eps 0.000100\n",
      "processing zhang2016\n",
      "solving primary acc 0.947600 sens 0.774300 spec 0.972500 eps 0.000100\n",
      "solving LID-OS acc 0.947400 sens 0.747300 spec 0.976400 eps 0.000100\n",
      "processing zhang2018\n",
      "solving primary acc 0.950400 sens 0.872300 spec 0.961800 eps 0.000100\n",
      "processing zhao2015\n",
      "solving primary acc 0.954000 sens 0.742000 spec 0.982000 eps 0.001000\n",
      "solving FR acc 0.853000 sens 0.686000 spec 0.867000 eps 0.001000\n",
      "solving WL acc 0.946000 sens 0.716000 spec 0.978000 eps 0.001000\n",
      "solving CV acc 0.939000 sens 0.679000 spec 0.924000 eps 0.001000\n",
      "solving IPAC acc 0.944000 sens 0.721000 spec 0.966000 eps 0.001000\n",
      "processing zhao2015b\n",
      "solving primary acc 0.953000 sens 0.744000 spec 0.978000 eps 0.001000\n",
      "solving no retinex acc 0.939000 sens 0.744000 spec 0.963000 eps 0.001000\n",
      "solving LP TV acc 0.930000 sens 0.702000 spec 0.949000 eps 0.001000\n",
      "solving LP LS acc 0.921000 sens 0.679000 spec 0.924000 eps 0.001000\n",
      "solving WL GC acc 0.921000 sens 0.744000 spec 0.923000 eps 0.001000\n",
      "solving WL TV acc 0.912000 sens 0.687000 spec 0.930000 eps 0.001000\n",
      "solving WL LS acc 0.914000 sens 0.691000 spec 0.934000 eps 0.001000\n",
      "solving FR GC acc 0.881000 sens 0.667000 spec 0.921000 eps 0.001000\n",
      "solving FR TV acc 0.893000 sens 0.722000 spec 0.921000 eps 0.001000\n",
      "solving FR LS acc 0.927000 sens 0.694000 spec 0.939000 eps 0.001000\n",
      "processing zhou2017\n",
      "solving primary acc 0.946900 sens 0.807800 spec 0.967400 eps 0.000100\n",
      "solving Table 5 row 2 acc 0.949000 sens 0.775800 spec 0.974700 eps 0.000100\n",
      "solving Table 5 row 3 acc 0.946700 sens 0.799900 spec 0.968300 eps 0.000100\n",
      "solving Table 5 row 4 acc 0.935400 sens 0.745900 spec 0.963200 eps 0.000100\n",
      "processing zhu2016\n",
      "solving primary acc 0.960700 sens 0.714000 spec 0.986800 eps 0.000100\n",
      "solving local features acc 0.950800 sens 0.583800 spec 0.988800 eps 0.000100\n",
      "solving morphological transformation acc 0.958100 sens 0.658000 spec 0.989300 eps 0.000100\n",
      "solving phase congruency acc 0.938900 sens 0.591300 spec 0.976100 eps 0.000100\n",
      "solving hessian features acc 0.942300 sens 0.561700 spec 0.981700 eps 0.000100\n",
      "solving divergence of vector field acc 0.943500 sens 0.417900 spec 0.997900 eps 0.000100\n",
      "solving svm acc 0.956800 sens 0.601800 spec 0.993600 eps 0.000100\n",
      "solving random forest acc 0.960800 sens 0.748200 spec 0.983500 eps 0.000100\n",
      "solving adaboost acc 0.957700 sens 0.786600 spec 0.976600 eps 0.000100\n",
      "processing dash2020\n",
      "solving primary acc 0.952000 sens 0.756000 spec 0.981000 eps 0.001000\n",
      "processing na2018\n",
      "solving primary acc 0.954000 sens 0.768000 spec 0.970000 eps 0.001000\n",
      "processing bharkad2017\n",
      "solving primary acc 0.950300 sens 0.727800 spec 0.971800 eps 0.000100\n",
      "processing lupascu2016\n",
      "solving primary acc 0.960600 sens 0.700600 spec 0.985700 eps 0.000100\n",
      "solving staple acc 0.957300 sens 0.747600 spec 0.977600 eps 0.000100\n",
      "processing kumar2020\n",
      "solving primary acc 0.943200 sens 0.750300 spec 0.971700 eps 0.000100\n",
      "processing rahmani2020\n",
      "solving primary acc 0.952100 sens 0.740000 spec 0.972600 eps 0.000100\n",
      "processing atli2020\n",
      "solving primary acc 0.968900 sens 0.798700 spec 0.985400 eps 0.000100\n",
      "solving pp acc 0.985000 sens 0.826000 spec 0.982400 eps 0.000100\n",
      "processing narkthewan2019\n",
      "solving primary acc 0.961700 sens 0.639200 spec 0.992000 eps 0.000100\n"
     ]
    }
   ],
   "source": [
    "num_figures= {}\n",
    "threshold= aggregated_threshold\n",
    "unique_keys= pd.unique(methods['key'])\n",
    "\n",
    "for key in unique_keys:\n",
    "    print('processing', key)\n",
    "    if key in num_figures:\n",
    "        num_figures[key]= num_figures[key] + 1\n",
    "    else:\n",
    "        num_figures[key]= 1\n",
    "\n",
    "    paper_scores= methods[methods['key'] == key]\n",
    "\n",
    "    results_fov_mor= []\n",
    "    results_no_fov_mor= []\n",
    "    results_fov_rom= []\n",
    "    results_no_fov_rom= []\n",
    "\n",
    "    for i, row in paper_scores.iterrows():\n",
    "        if exclude_stare_training:\n",
    "            if 'stare' in row['flag'].lower():\n",
    "                continue\n",
    "\n",
    "        eps= 10**(-row['digits'])\n",
    "\n",
    "        print('solving %s acc %f sens %f spec %f eps %f' % (row['flag'], row['acc'], row['sens'], row['spec'], eps))\n",
    "\n",
    "        results_fov_mor.append(consistency_aggregated_integer_programming_mor(data_test_with_fov_obs1['p'].values, \n",
    "                                                                                data_test_with_fov_obs1['n'].values, \n",
    "                                                                                row['acc'], \n",
    "                                                                                row['sens'], \n",
    "                                                                                row['spec'], \n",
    "                                                                                eps))\n",
    "        results_no_fov_mor.append(consistency_aggregated_integer_programming_mor(data_test_without_fov_obs1['p'].values, \n",
    "                                                                                    data_test_without_fov_obs1['n'].values, \n",
    "                                                                                    row['acc'], \n",
    "                                                                                    row['sens'], \n",
    "                                                                                    row['spec'], \n",
    "                                                                                    eps))\n",
    "        results_fov_rom.append(consistency_aggregated_integer_programming_rom(data_test_with_fov_obs1['p'].values, \n",
    "                                                                                data_test_with_fov_obs1['n'].values, \n",
    "                                                                                row['acc'], \n",
    "                                                                                row['sens'], \n",
    "                                                                                row['spec'], \n",
    "                                                                                eps))\n",
    "        results_no_fov_rom.append(consistency_aggregated_integer_programming_rom(data_test_without_fov_obs1['p'].values, \n",
    "                                                                                    data_test_without_fov_obs1['n'].values, \n",
    "                                                                                    row['acc'], \n",
    "                                                                                    row['sens'], \n",
    "                                                                                    row['spec'], \n",
    "                                                                                    eps))\n",
    "    il_results.loc[key, 'n_aggregated_scores']= len(results_fov_mor)\n",
    "    il_results.loc[key, 'consistency_with_fov_mor']= np.mean(np.array(results_fov_mor)*1.0)\n",
    "    il_results.loc[key, 'consistency_without_fov_mor']= np.mean(np.array(results_no_fov_mor)*1.0)\n",
    "    il_results.loc[key, 'consistency_with_fov_rom']= np.mean(np.array(results_fov_rom)*1.0)\n",
    "    il_results.loc[key, 'consistency_without_fov_rom']= np.mean(np.array(results_no_fov_rom)*1.0)\n",
    "    il_results.loc[key, 'consistency_with_fov']= (results_fov_mor[0] and il_results.loc[key, 'consistency_with_fov_mor'] > threshold) or (results_fov_rom[0] and il_results.loc[key, 'consistency_with_fov_rom'] > threshold)\n",
    "    il_results.loc[key, 'consistency_without_fov']= (results_no_fov_mor[0] and il_results.loc[key, 'consistency_without_fov_mor'] > threshold) or (results_no_fov_rom[0] and il_results.loc[key, 'consistency_without_fov_rom'] > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods= il_results"
   ]
  },
  {
   "source": [
    "## The analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all= methods.copy()\n",
    "\n",
    "all.loc[all['consistency_with_fov'], 'category_agg']= 'FoV'\n",
    "all.loc[all['consistency_without_fov'], 'category_agg']= 'no FoV'\n",
    "all.loc[all['consistency_with_fov'] & all['consistency_without_fov'], 'category_agg']= 'ambiguous'\n",
    "all.loc[(~all['category_agg'].isin(['FoV',\n",
    "                                        'no FoV',\n",
    "                                        'excluded',\n",
    "                                        'ambiguous'])), 'category_agg']= 'outlier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced= all[all['category'].isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              key\n",
       "category_agg     \n",
       "FoV            30\n",
       "no FoV         18\n",
       "outlier        16"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n    </tr>\n    <tr>\n      <th>category_agg</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>FoV</th>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>no FoV</th>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>outlier</th>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "reduced[['key', 'category_agg']].groupby('category_agg').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                Key $\\overline{acc}$ $\\overline{sens}$ $\\overline{spec}$  \\rotatebox{90}{Decimal places}  \\rotatebox{90}{Num. agg. figures} \\rotatebox{90}{$H_{\\text{FoV}}$ not rejected} \\rotatebox{90}{$H_{all}$ not rejected}    Decision\n",
       "0                   \\cite{alom2019}            .9613             .7661             .9807                               4                                  1                                                                                          outlier\n",
       "1               \\cite{anzalone2008}            .9418             .7286             .9810                               4                                  1                                                                                          outlier\n",
       "2              \\cite{azzopardi2014}            .9442             .7655             .9704                               4                                  1                                             +                                                FoV\n",
       "3               \\cite{brancati2018}            .9490             .7820             .9760                               3                                  1                                             +                                                FoV\n",
       "4                  \\cite{budai2013}            .9570             .6440             .9870                               3                                  1                                                                                    +  all pixels\n",
       "5              \\cite{chalakkal2017}            .9518             .7386             .9769                               4                                  1                                                                                          outlier\n",
       "6                  \\cite{cheng2014}            .9474             .7252             .9798                               4                                  1                                             +                                                FoV\n",
       "7                    \\cite{dai2015}            .9418             .7359             .9720                               4                                  1                                             +                                                FoV\n",
       "8               \\cite{dasgupta2017}            .9533             .7691             .9801                               4                                  1                                             +                                                FoV\n",
       "9             \\cite{dizdaroglu2012}            .9412             .7181             .9743                               4                                  1                                                                                          outlier\n",
       "10                   \\cite{fan2017}            .9600             .7360             .9810                               3                                  1                                                                                    +  all pixels\n",
       "11                \\cite{frucci2017}            .9560             .6600             .9850                               3                                  1                                                                                    +  all pixels\n",
       "12                    \\cite{hu2018}            .9533             .7796             .9717                               4                                  1                                                                                          outlier\n",
       "13                \\cite{javidi2017}            .9450             .7201             .9702                               4                                  1                                                                                    +  all pixels\n",
       "14             \\cite{jebaseeli2019}            .9898             .8027             .9980                               4                                  1                                                                                          outlier\n",
       "15                 \\cite{jiang2019}            .9706             .8325             .9838                               4                                  1                                                                                    +  all pixels\n",
       "16                  \\cite{kaur2017}            .9480             .8730             .9869                               4                                  1                                                                                          outlier\n",
       "17                \\cite{kovacs2016}            .9494             .7450             .9793                               4                                  1                                             +                                                FoV\n",
       "18                 \\cite{kumar2016}            .9626             .7006             .9871                               4                                  1                                                                                    +  all pixels\n",
       "19             \\cite{liskowski2016}            .9535             .7811             .9807                               4                                  1                                             +                                                FoV\n",
       "20                \\cite{mapayi2015}            .9511             .7313             .9724                               4                                  1                                                                                    +  all pixels\n",
       "21             \\cite{melinscak2015}            .9466             .7276             .9785                               4                                  1                                             +                                                FoV\n",
       "22                \\cite{memari2017}            .9722             .8726             .9884                               4                                  1                                                                                          outlier\n",
       "23              \\cite{mendonca2006}            .9463             .7315             .9781                               4                                  1                                             +                                                FoV\n",
       "24                  \\cite{miri2011}            .9458             .7352             .9795                               4                                  1                                             +                                                FoV\n",
       "25                \\cite{nazari2013}            .9481             .7112             .9716                               4                                  1                                                                                    +  all pixels\n",
       "26                   \\cite{ngo2017}            .9533             .7464             .9836                               4                                  1                                             +                                                FoV\n",
       "27                   \\cite{noh2019}            .9569             .8354             .9746                               4                                  1                                             +                                                FoV\n",
       "28             \\cite{palanivel2020}            .9480             .7375             .9788                               4                                  1                                             +                                                FoV\n",
       "29                   \\cite{pan2019}            .9650             .8150             .9808                               4                                  1                                                                                    +  all pixels\n",
       "30                 \\cite{panda2016}            .9539             .7328             .9752                               4                                  1                                                                                    +  all pixels\n",
       "31                \\cite{pandey2016}            .9623             .8106             .9761                               4                                  1                                                                                    +  all pixels\n",
       "32                  \\cite{park2020}            .9706             .8346             .9836                               4                                  1                                                                                    +  all pixels\n",
       "33                \\cite{rezaee2017}            .9463             .7189             .9793                               4                                  1                                             +                                                FoV\n",
       "34          \\cite{roychowdhury2015}            .9494             .7395             .9782                               4                                  1                                             +                                                FoV\n",
       "35      \\cite{salazar-gonzalez2014}            .9412             .7512             .9684                               4                                  1                                             +                                                FoV\n",
       "36                 \\cite{saleh2011}            .9630             .8423             .9658                               4                                  1                                                                                          outlier\n",
       "37                \\cite{samuel2019}            .9609             .8282             .9738                               4                                  1                                                                                    +  all pixels\n",
       "38                  \\cite{shah2017}            .9479             .7205             .9814                               4                                  1                                             +                                                FoV\n",
       "39                \\cite{shukla2020}            .9476             .7015             .9836                               4                                  1                                             +                                                FoV\n",
       "40                  \\cite{song2017}            .9499             .7501             .9795                               4                                  1                                             +                                                FoV\n",
       "41                \\cite{soomro2017}            .9432             .7523             .9760                               4                                  1                                             +                                                FoV\n",
       "42                \\cite{soomro2018}            .9534             .7592             .9763                               4                                  1                                                                                          outlier\n",
       "43                \\cite{soomro2019}            .9560             .8700             .9850                               3                                  1                                                                                          outlier\n",
       "44              \\cite{sreejini2015}            .9633             .7132             .9866                               4                                  1                                                                                    +  all pixels\n",
       "45                 \\cite{staal2004}            .9441             .7750             .9725                               4                                  1                                             +                                                FoV\n",
       "46          \\cite{strisciuglio2015}            .9442             .7655             .9704                               4                                  1                                             +                                                FoV\n",
       "47          \\cite{strisciuglio2016}            .9454             .7777             .9702                               4                                  1                                             +                                                FoV\n",
       "48   \\cite{villalobos-castaldi2010}            .9759             .9649             .9480                               4                                  1                                                                                          outlier\n",
       "49              \\cite{wankhede2015}            .9626             .7261             .9806                               4                                  1                                                                                          outlier\n",
       "50                    \\cite{wu2020}            .9582             .7996             .9813                               4                                  1                                             +                                                FoV\n",
       "51                 \\cite{xiang2014}            .9613             .7538             .9828                               4                                  1                                                                                    +  all pixels\n",
       "52                   \\cite{yan2018}            .9542             .7653             .9818                               4                                  1                                             +                                                FoV\n",
       "53                  \\cite{yang2020}            .9532             .7349             .9743                               4                                  1                                                                                    +  all pixels\n",
       "54                   \\cite{you2011}            .9434             .7410             .9751                               4                                  1                                             +                                                FoV\n",
       "55                 \\cite{zhang2010}            .9382             .7120             .9724                               4                                  1                                             +                                                FoV\n",
       "56                 \\cite{zhang2016}            .9476             .7743             .9725                               4                                  1                                             +                                                FoV\n",
       "57                 \\cite{zhang2018}            .9504             .8723             .9618                               4                                  1                                             +                                                FoV\n",
       "58                  \\cite{zhao2015}            .9540             .7420             .9820                               3                                  1                                                                                          outlier\n",
       "59                 \\cite{zhao2015b}            .9530             .7440             .9780                               3                                  1                                                                                          outlier\n",
       "60                  \\cite{zhou2017}            .9469             .8078             .9674                               4                                  1                                             +                                                FoV\n",
       "61                    \\cite{na2018}            .9540             .7680             .9700                               3                                  1                                                                                    +  all pixels\n",
       "62               \\cite{rahmani2020}            .9521             .7400             .9726                               4                                  1                                                                                    +  all pixels\n",
       "63                  \\cite{atli2020}            .9689             .7987             .9854                               4                                  1                                                                                          outlier"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Key</th>\n      <th>$\\overline{acc}$</th>\n      <th>$\\overline{sens}$</th>\n      <th>$\\overline{spec}$</th>\n      <th>\\rotatebox{90}{Decimal places}</th>\n      <th>\\rotatebox{90}{Num. agg. figures}</th>\n      <th>\\rotatebox{90}{$H_{\\text{FoV}}$ not rejected}</th>\n      <th>\\rotatebox{90}{$H_{all}$ not rejected}</th>\n      <th>Decision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\cite{alom2019}</td>\n      <td>.9613</td>\n      <td>.7661</td>\n      <td>.9807</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\cite{anzalone2008}</td>\n      <td>.9418</td>\n      <td>.7286</td>\n      <td>.9810</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\cite{azzopardi2014}</td>\n      <td>.9442</td>\n      <td>.7655</td>\n      <td>.9704</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\cite{brancati2018}</td>\n      <td>.9490</td>\n      <td>.7820</td>\n      <td>.9760</td>\n      <td>3</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\\cite{budai2013}</td>\n      <td>.9570</td>\n      <td>.6440</td>\n      <td>.9870</td>\n      <td>3</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>\\cite{chalakkal2017}</td>\n      <td>.9518</td>\n      <td>.7386</td>\n      <td>.9769</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>\\cite{cheng2014}</td>\n      <td>.9474</td>\n      <td>.7252</td>\n      <td>.9798</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>\\cite{dai2015}</td>\n      <td>.9418</td>\n      <td>.7359</td>\n      <td>.9720</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>\\cite{dasgupta2017}</td>\n      <td>.9533</td>\n      <td>.7691</td>\n      <td>.9801</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>\\cite{dizdaroglu2012}</td>\n      <td>.9412</td>\n      <td>.7181</td>\n      <td>.9743</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>\\cite{fan2017}</td>\n      <td>.9600</td>\n      <td>.7360</td>\n      <td>.9810</td>\n      <td>3</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>\\cite{frucci2017}</td>\n      <td>.9560</td>\n      <td>.6600</td>\n      <td>.9850</td>\n      <td>3</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>\\cite{hu2018}</td>\n      <td>.9533</td>\n      <td>.7796</td>\n      <td>.9717</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>\\cite{javidi2017}</td>\n      <td>.9450</td>\n      <td>.7201</td>\n      <td>.9702</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>\\cite{jebaseeli2019}</td>\n      <td>.9898</td>\n      <td>.8027</td>\n      <td>.9980</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>\\cite{jiang2019}</td>\n      <td>.9706</td>\n      <td>.8325</td>\n      <td>.9838</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>\\cite{kaur2017}</td>\n      <td>.9480</td>\n      <td>.8730</td>\n      <td>.9869</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>\\cite{kovacs2016}</td>\n      <td>.9494</td>\n      <td>.7450</td>\n      <td>.9793</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>\\cite{kumar2016}</td>\n      <td>.9626</td>\n      <td>.7006</td>\n      <td>.9871</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>\\cite{liskowski2016}</td>\n      <td>.9535</td>\n      <td>.7811</td>\n      <td>.9807</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>\\cite{mapayi2015}</td>\n      <td>.9511</td>\n      <td>.7313</td>\n      <td>.9724</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>\\cite{melinscak2015}</td>\n      <td>.9466</td>\n      <td>.7276</td>\n      <td>.9785</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>\\cite{memari2017}</td>\n      <td>.9722</td>\n      <td>.8726</td>\n      <td>.9884</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>\\cite{mendonca2006}</td>\n      <td>.9463</td>\n      <td>.7315</td>\n      <td>.9781</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>\\cite{miri2011}</td>\n      <td>.9458</td>\n      <td>.7352</td>\n      <td>.9795</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>\\cite{nazari2013}</td>\n      <td>.9481</td>\n      <td>.7112</td>\n      <td>.9716</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>\\cite{ngo2017}</td>\n      <td>.9533</td>\n      <td>.7464</td>\n      <td>.9836</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>\\cite{noh2019}</td>\n      <td>.9569</td>\n      <td>.8354</td>\n      <td>.9746</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>\\cite{palanivel2020}</td>\n      <td>.9480</td>\n      <td>.7375</td>\n      <td>.9788</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>\\cite{pan2019}</td>\n      <td>.9650</td>\n      <td>.8150</td>\n      <td>.9808</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>\\cite{panda2016}</td>\n      <td>.9539</td>\n      <td>.7328</td>\n      <td>.9752</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>\\cite{pandey2016}</td>\n      <td>.9623</td>\n      <td>.8106</td>\n      <td>.9761</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>\\cite{park2020}</td>\n      <td>.9706</td>\n      <td>.8346</td>\n      <td>.9836</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>\\cite{rezaee2017}</td>\n      <td>.9463</td>\n      <td>.7189</td>\n      <td>.9793</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>\\cite{roychowdhury2015}</td>\n      <td>.9494</td>\n      <td>.7395</td>\n      <td>.9782</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>\\cite{salazar-gonzalez2014}</td>\n      <td>.9412</td>\n      <td>.7512</td>\n      <td>.9684</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>\\cite{saleh2011}</td>\n      <td>.9630</td>\n      <td>.8423</td>\n      <td>.9658</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>\\cite{samuel2019}</td>\n      <td>.9609</td>\n      <td>.8282</td>\n      <td>.9738</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>\\cite{shah2017}</td>\n      <td>.9479</td>\n      <td>.7205</td>\n      <td>.9814</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>\\cite{shukla2020}</td>\n      <td>.9476</td>\n      <td>.7015</td>\n      <td>.9836</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>\\cite{song2017}</td>\n      <td>.9499</td>\n      <td>.7501</td>\n      <td>.9795</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>\\cite{soomro2017}</td>\n      <td>.9432</td>\n      <td>.7523</td>\n      <td>.9760</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>\\cite{soomro2018}</td>\n      <td>.9534</td>\n      <td>.7592</td>\n      <td>.9763</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>\\cite{soomro2019}</td>\n      <td>.9560</td>\n      <td>.8700</td>\n      <td>.9850</td>\n      <td>3</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>\\cite{sreejini2015}</td>\n      <td>.9633</td>\n      <td>.7132</td>\n      <td>.9866</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>\\cite{staal2004}</td>\n      <td>.9441</td>\n      <td>.7750</td>\n      <td>.9725</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>\\cite{strisciuglio2015}</td>\n      <td>.9442</td>\n      <td>.7655</td>\n      <td>.9704</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>\\cite{strisciuglio2016}</td>\n      <td>.9454</td>\n      <td>.7777</td>\n      <td>.9702</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>\\cite{villalobos-castaldi2010}</td>\n      <td>.9759</td>\n      <td>.9649</td>\n      <td>.9480</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>\\cite{wankhede2015}</td>\n      <td>.9626</td>\n      <td>.7261</td>\n      <td>.9806</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>\\cite{wu2020}</td>\n      <td>.9582</td>\n      <td>.7996</td>\n      <td>.9813</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>\\cite{xiang2014}</td>\n      <td>.9613</td>\n      <td>.7538</td>\n      <td>.9828</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>\\cite{yan2018}</td>\n      <td>.9542</td>\n      <td>.7653</td>\n      <td>.9818</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>\\cite{yang2020}</td>\n      <td>.9532</td>\n      <td>.7349</td>\n      <td>.9743</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>\\cite{you2011}</td>\n      <td>.9434</td>\n      <td>.7410</td>\n      <td>.9751</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>\\cite{zhang2010}</td>\n      <td>.9382</td>\n      <td>.7120</td>\n      <td>.9724</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>\\cite{zhang2016}</td>\n      <td>.9476</td>\n      <td>.7743</td>\n      <td>.9725</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>\\cite{zhang2018}</td>\n      <td>.9504</td>\n      <td>.8723</td>\n      <td>.9618</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>\\cite{zhao2015}</td>\n      <td>.9540</td>\n      <td>.7420</td>\n      <td>.9820</td>\n      <td>3</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>\\cite{zhao2015b}</td>\n      <td>.9530</td>\n      <td>.7440</td>\n      <td>.9780</td>\n      <td>3</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>\\cite{zhou2017}</td>\n      <td>.9469</td>\n      <td>.8078</td>\n      <td>.9674</td>\n      <td>4</td>\n      <td>1</td>\n      <td>+</td>\n      <td></td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>\\cite{na2018}</td>\n      <td>.9540</td>\n      <td>.7680</td>\n      <td>.9700</td>\n      <td>3</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>\\cite{rahmani2020}</td>\n      <td>.9521</td>\n      <td>.7400</td>\n      <td>.9726</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td>+</td>\n      <td>all pixels</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>\\cite{atli2020}</td>\n      <td>.9689</td>\n      <td>.7987</td>\n      <td>.9854</td>\n      <td>4</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>outlier</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# preparing latex table\n",
    "latex= reduced[['key', 'acc', 'sens', 'spec', 'digits', 'consistency_with_fov', 'consistency_without_fov', 'category_agg']].copy()\n",
    "latex['num_figures']= latex['key'].apply(lambda x: num_figures[x])\n",
    "latex= latex[['key', 'acc', 'sens', 'spec', 'digits', 'num_figures', 'consistency_with_fov', 'consistency_without_fov', 'category_agg']]\n",
    "latex.loc[latex['category_agg'] == 'no FoV', 'category_agg']= 'all pixels'\n",
    "latex['key']= latex['key'].apply(lambda x: x[0:1].upper() + x[1:])\n",
    "latex['key']= latex['key'].apply(lambda x: ' \\cite{' + x.lower() + '}')\n",
    "latex['digits']= latex['digits'].astype(int)\n",
    "latex['num_figures']= latex['num_figures'].astype(int)\n",
    "latex['acc']= latex['acc'].apply(lambda x: ('%.4f' % x)[1:])\n",
    "latex['sens']= latex['sens'].apply(lambda x: ('%.4f' % x)[1:])\n",
    "latex['spec']= latex['spec'].apply(lambda x: ('%.4f' % x)[1:])\n",
    "latex['consistency_with_fov']= latex['consistency_with_fov'].apply(lambda x: '+' if x else '')\n",
    "latex['consistency_without_fov']= latex['consistency_without_fov'].apply(lambda x: '+' if x else '')\n",
    "latex.columns=['Key', '$\\overline{acc}$', '$\\overline{sens}$', '$\\overline{spec}$', '\\rotatebox{90}{Decimal places}', '\\rotatebox{90}{Num. agg. figures}', '\\rotatebox{90}{$H_{\\text{FoV}}$ not rejected}', '\\rotatebox{90}{$H_{all}$ not rejected}', 'Decision']\n",
    "latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_str= set_column_spaces(latex.sort_values('$\\overline{acc}$', ascending=False).to_latex(escape=False, index=False), n_cols=9)\n",
    "with open(os.path.join(latex_dir, \"tab3.tex\"), \"w\") as text_file:\n",
    "    text_file.write(latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "category_agg=outlier<br>acc=%{x}<br>spec=%{y}<br>key=%{text}<extra></extra>",
         "legendgroup": "outlier",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "outlier",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "alom2019",
          "anzalone2008",
          "chalakkal2017",
          "dizdaroglu2012",
          "hu2018",
          "jebaseeli2019",
          "kaur2017",
          "memari2017",
          "saleh2011",
          "soomro2018",
          "soomro2019",
          "villalobos-castaldi2010",
          "wankhede2015",
          "zhao2015",
          "zhao2015b",
          "atli2020"
         ],
         "type": "scatter",
         "x": [
          0.9613,
          0.9418,
          0.9518,
          0.9412,
          0.9533,
          0.9898,
          0.948,
          0.9722,
          0.963,
          0.9534,
          0.956,
          0.9759,
          0.9626,
          0.9540000000000001,
          0.953,
          0.9689
         ],
         "xaxis": "x",
         "y": [
          0.9807,
          0.981,
          0.9769,
          0.9743,
          0.9717,
          0.998,
          0.9869,
          0.9884,
          0.9658,
          0.9763,
          0.985,
          0.948,
          0.9806,
          0.982,
          0.978,
          0.9854
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "category_agg=FoV<br>acc=%{x}<br>spec=%{y}<br>key=%{text}<extra></extra>",
         "legendgroup": "FoV",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "FoV",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "azzopardi2014",
          "brancati2018",
          "cheng2014",
          "dai2015",
          "dasgupta2017",
          "kovacs2016",
          "liskowski2016",
          "melinscak2015",
          "mendonca2006",
          "miri2011",
          "ngo2017",
          "noh2019",
          "palanivel2020",
          "rezaee2017",
          "roychowdhury2015",
          "salazar-gonzalez2014",
          "shah2017",
          "shukla2020",
          "song2017",
          "soomro2017",
          "staal2004",
          "strisciuglio2015",
          "strisciuglio2016",
          "wu2020",
          "yan2018",
          "you2011",
          "zhang2010",
          "zhang2016",
          "zhang2018",
          "zhou2017"
         ],
         "type": "scatter",
         "x": [
          0.9442,
          0.9490000000000001,
          0.9474,
          0.9418,
          0.9533,
          0.9494,
          0.9535,
          0.9466,
          0.9463,
          0.9458,
          0.9533,
          0.9569,
          0.948,
          0.9463,
          0.9494,
          0.9412,
          0.9479,
          0.9476,
          0.9499,
          0.9432,
          0.9441,
          0.9442,
          0.9454,
          0.9582,
          0.9542,
          0.9434,
          0.9382,
          0.9476,
          0.9504,
          0.9469
         ],
         "xaxis": "x",
         "y": [
          0.9704,
          0.976,
          0.9798,
          0.972,
          0.9801,
          0.9793,
          0.9807,
          0.9785,
          0.9781,
          0.9795,
          0.9836,
          0.9746,
          0.9788,
          0.9793,
          0.9782,
          0.9684,
          0.9814,
          0.9836,
          0.9795,
          0.976,
          0.9725,
          0.9704,
          0.9702,
          0.9813,
          0.9818,
          0.9751,
          0.9724,
          0.9725,
          0.9618,
          0.9674
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "category_agg=no FoV<br>acc=%{x}<br>spec=%{y}<br>key=%{text}<extra></extra>",
         "legendgroup": "no FoV",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "no FoV",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "budai2013",
          "fan2017",
          "frucci2017",
          "javidi2017",
          "jiang2019",
          "kumar2016",
          "mapayi2015",
          "nazari2013",
          "pan2019",
          "panda2016",
          "pandey2016",
          "park2020",
          "samuel2019",
          "sreejini2015",
          "xiang2014",
          "yang2020",
          "na2018",
          "rahmani2020"
         ],
         "type": "scatter",
         "x": [
          0.9570000000000001,
          0.96,
          0.956,
          0.945,
          0.9706,
          0.9626,
          0.9511,
          0.9481,
          0.965,
          0.9539,
          0.9623,
          0.9706,
          0.9609,
          0.9633,
          0.9613,
          0.9532,
          0.9540000000000001,
          0.9521
         ],
         "xaxis": "x",
         "y": [
          0.987,
          0.981,
          0.985,
          0.9702,
          0.9838,
          0.9871,
          0.9724,
          0.9716,
          0.9808,
          0.9752,
          0.9761,
          0.9836,
          0.9738,
          0.9866,
          0.9828,
          0.9743,
          0.97,
          0.9726
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 1000,
        "legend": {
         "title": {
          "text": "category_agg"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "acc"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "spec"
         }
        }
       }
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "px.scatter(reduced[reduced['category_agg'].notnull()], x='acc', y='spec', text='key', color='category_agg', width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"331.953548pt\" version=\"1.1\" viewBox=\"0 0 352.49375 331.953548\" width=\"352.49375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-21T11:17:46.146707</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 331.953548 \nL 352.49375 331.953548 \nL 352.49375 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 294.397298 \nL 345.29375 294.397298 \nL 345.29375 8.399236 \nL 50.14375 8.399236 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 5 \nC 1.326016 5 2.597899 4.473168 3.535534 3.535534 \nC 4.473168 2.597899 5 1.326016 5 0 \nC 5 -1.326016 4.473168 -2.597899 3.535534 -3.535534 \nC 2.597899 -4.473168 1.326016 -5 0 -5 \nC -1.326016 -5 -2.597899 -4.473168 -3.535534 -3.535534 \nC -4.473168 -2.597899 -5 -1.326016 -5 0 \nC -5 1.326016 -4.473168 2.597899 -3.535534 3.535534 \nC -2.597899 4.473168 -1.326016 5 0 5 \nz\n\" id=\"m6663ee2562\" style=\"stroke:#1f77b4;\"/>\n    </defs>\n    <g clip-path=\"url(#p556d2812f9)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.759448\" xlink:href=\"#m6663ee2562\" y=\"164.918176\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"119.719279\" xlink:href=\"#m6663ee2562\" y=\"135.798373\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"111.399335\" xlink:href=\"#m6663ee2562\" y=\"116.038507\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"82.279532\" xlink:href=\"#m6663ee2562\" y=\"156.598232\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"142.079127\" xlink:href=\"#m6663ee2562\" y=\"114.478518\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"121.799264\" xlink:href=\"#m6663ee2562\" y=\"118.638489\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"143.11912\" xlink:href=\"#m6663ee2562\" y=\"111.358539\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"107.239363\" xlink:href=\"#m6663ee2562\" y=\"122.798461\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"105.679374\" xlink:href=\"#m6663ee2562\" y=\"124.878447\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"103.079391\" xlink:href=\"#m6663ee2562\" y=\"117.598496\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"142.079127\" xlink:href=\"#m6663ee2562\" y=\"96.278641\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"160.799\" xlink:href=\"#m6663ee2562\" y=\"143.078324\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"114.519314\" xlink:href=\"#m6663ee2562\" y=\"121.238472\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"105.679374\" xlink:href=\"#m6663ee2562\" y=\"118.638489\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"121.799264\" xlink:href=\"#m6663ee2562\" y=\"124.358451\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"79.159553\" xlink:href=\"#m6663ee2562\" y=\"175.318105\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.999317\" xlink:href=\"#m6663ee2562\" y=\"107.718563\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"112.439328\" xlink:href=\"#m6663ee2562\" y=\"96.278641\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"124.399247\" xlink:href=\"#m6663ee2562\" y=\"117.598496\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"89.559483\" xlink:href=\"#m6663ee2562\" y=\"135.798373\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.239451\" xlink:href=\"#m6663ee2562\" y=\"153.99825\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.759448\" xlink:href=\"#m6663ee2562\" y=\"164.918176\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"100.999405\" xlink:href=\"#m6663ee2562\" y=\"165.958169\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"167.558954\" xlink:href=\"#m6663ee2562\" y=\"108.23856\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"146.759095\" xlink:href=\"#m6663ee2562\" y=\"105.638577\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"90.599476\" xlink:href=\"#m6663ee2562\" y=\"140.478341\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"63.559659\" xlink:href=\"#m6663ee2562\" y=\"154.518246\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"112.439328\" xlink:href=\"#m6663ee2562\" y=\"153.99825\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"126.999229\" xlink:href=\"#m6663ee2562\" y=\"209.637873\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"108.799353\" xlink:href=\"#m6663ee2562\" y=\"180.51807\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_2\">\n    <defs>\n     <path d=\"M -5 5 \nL 5 5 \nL 5 -5 \nL -5 -5 \nz\n\" id=\"m34d0ea9bc2\" style=\"stroke:#ff7f0e;\"/>\n    </defs>\n    <g clip-path=\"url(#p556d2812f9)\">\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"161.318997\" xlink:href=\"#m34d0ea9bc2\" y=\"78.598761\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"176.918891\" xlink:href=\"#m34d0ea9bc2\" y=\"109.798549\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"156.119032\" xlink:href=\"#m34d0ea9bc2\" y=\"88.99869\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"98.919419\" xlink:href=\"#m34d0ea9bc2\" y=\"165.958169\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"232.038517\" xlink:href=\"#m34d0ea9bc2\" y=\"95.238648\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"190.438799\" xlink:href=\"#m34d0ea9bc2\" y=\"78.078764\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"130.639205\" xlink:href=\"#m34d0ea9bc2\" y=\"154.518246\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"115.03931\" xlink:href=\"#m34d0ea9bc2\" y=\"158.678218\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"202.918715\" xlink:href=\"#m34d0ea9bc2\" y=\"110.838542\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"145.199106\" xlink:href=\"#m34d0ea9bc2\" y=\"139.958345\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"188.87881\" xlink:href=\"#m34d0ea9bc2\" y=\"135.278377\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"232.038517\" xlink:href=\"#m34d0ea9bc2\" y=\"96.278641\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"181.598859\" xlink:href=\"#m34d0ea9bc2\" y=\"147.238296\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"194.078775\" xlink:href=\"#m34d0ea9bc2\" y=\"80.678747\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"183.678845\" xlink:href=\"#m34d0ea9bc2\" y=\"100.438613\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"141.559131\" xlink:href=\"#m34d0ea9bc2\" y=\"144.638313\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"145.719102\" xlink:href=\"#m34d0ea9bc2\" y=\"166.998162\"/>\n     <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"135.839169\" xlink:href=\"#m34d0ea9bc2\" y=\"153.478253\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_3\">\n    <defs>\n     <path d=\"M -5 0 \nL 5 0 \nM 0 5 \nL 0 -5 \n\" id=\"ma1d09d7334\" style=\"stroke:#2ca02c;stroke-width:1.5;\"/>\n    </defs>\n    <g clip-path=\"url(#p556d2812f9)\">\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"183.678845\" xlink:href=\"#ma1d09d7334\" y=\"111.358539\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"82.279532\" xlink:href=\"#ma1d09d7334\" y=\"109.798549\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"134.27918\" xlink:href=\"#ma1d09d7334\" y=\"131.118405\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"79.159553\" xlink:href=\"#ma1d09d7334\" y=\"144.638313\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"142.079127\" xlink:href=\"#ma1d09d7334\" y=\"158.158222\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"331.877841\" xlink:href=\"#ma1d09d7334\" y=\"21.399148\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"114.519314\" xlink:href=\"#ma1d09d7334\" y=\"79.118757\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"240.358461\" xlink:href=\"#ma1d09d7334\" y=\"71.31881\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"192.518785\" xlink:href=\"#ma1d09d7334\" y=\"188.838014\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"142.599124\" xlink:href=\"#ma1d09d7334\" y=\"134.238384\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"156.119032\" xlink:href=\"#ma1d09d7334\" y=\"88.99869\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"259.598331\" xlink:href=\"#ma1d09d7334\" y=\"281.397386\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"190.438799\" xlink:href=\"#ma1d09d7334\" y=\"111.878535\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"145.719102\" xlink:href=\"#ma1d09d7334\" y=\"104.598585\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"140.519138\" xlink:href=\"#ma1d09d7334\" y=\"125.398444\"/>\n     <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"223.198577\" xlink:href=\"#ma1d09d7334\" y=\"86.918704\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_4\">\n    <defs>\n     <path d=\"M -0 10 \nL 10 0 \nL 0 -10 \nL -10 -0 \nz\n\" id=\"md0a05cfca0\" style=\"stroke:#d62728;\"/>\n    </defs>\n    <g clip-path=\"url(#p556d2812f9)\">\n     <use style=\"fill:#d62728;stroke:#d62728;\" x=\"110.879338\" xlink:href=\"#md0a05cfca0\" y=\"153.99825\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_5\">\n    <defs>\n     <path d=\"M 0 -8.660254 \nL -1.944348 -2.676166 \nL -8.236391 -2.676166 \nL -3.146021 1.022204 \nL -5.09037 7.006293 \nL -0 3.307923 \nL 5.09037 7.006293 \nL 3.146021 1.022204 \nL 8.236391 -2.676166 \nL 1.944348 -2.676166 \nz\n\" id=\"m98aebe8425\" style=\"stroke:#9467bd;\"/>\n    </defs>\n    <g clip-path=\"url(#p556d2812f9)\">\n     <use style=\"fill:#9467bd;stroke:#9467bd;\" x=\"195.638764\" xlink:href=\"#m98aebe8425\" y=\"105.638577\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m167191b695\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"72.919596\" xlink:href=\"#m167191b695\" y=\"294.397298\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.94 -->\n      <g transform=\"translate(61.786783 308.995736)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n        <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"124.919243\" xlink:href=\"#m167191b695\" y=\"294.397298\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.95 -->\n      <g transform=\"translate(113.786431 308.995736)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"176.918891\" xlink:href=\"#m167191b695\" y=\"294.397298\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.96 -->\n      <g transform=\"translate(165.786078 308.995736)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"228.918539\" xlink:href=\"#m167191b695\" y=\"294.397298\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.97 -->\n      <g transform=\"translate(217.785726 308.995736)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"280.918186\" xlink:href=\"#m167191b695\" y=\"294.397298\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.98 -->\n      <g transform=\"translate(269.785374 308.995736)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"332.917834\" xlink:href=\"#m167191b695\" y=\"294.397298\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.99 -->\n      <g transform=\"translate(321.785021 308.995736)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Accuracy -->\n     <g transform=\"translate(174.890625 322.673861)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"121.638672\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"176.619141\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"239.998047\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"281.111328\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"342.390625\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"397.371094\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"me4ff5b9655\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#me4ff5b9655\" y=\"270.997457\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.95 -->\n      <g transform=\"translate(20.878125 274.796676)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#me4ff5b9655\" y=\"218.997809\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.96 -->\n      <g transform=\"translate(20.878125 222.797028)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#me4ff5b9655\" y=\"166.998162\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.97 -->\n      <g transform=\"translate(20.878125 170.79738)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#me4ff5b9655\" y=\"114.998514\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.98 -->\n      <g transform=\"translate(20.878125 118.797733)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#me4ff5b9655\" y=\"62.998866\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.99 -->\n      <g transform=\"translate(20.878125 66.798085)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#me4ff5b9655\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.00 -->\n      <g transform=\"translate(20.878125 14.798438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- Specificity -->\n     <g transform=\"translate(14.798438 177.16858)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.953125\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"188.476562\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"243.457031\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"271.240234\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"306.445312\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"334.228516\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"389.208984\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"416.992188\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"456.201172\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 294.397298 \nL 50.14375 8.399236 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 345.29375 294.397298 \nL 345.29375 8.399236 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 294.397298 \nL 345.29375 294.397298 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 8.399236 \nL 345.29375 8.399236 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 57.14375 289.397298 \nL 201.064063 289.397298 \nQ 203.064063 289.397298 203.064063 287.397298 \nL 203.064063 215.006673 \nQ 203.064063 213.006673 201.064063 213.006673 \nL 57.14375 213.006673 \nQ 55.14375 213.006673 55.14375 215.006673 \nL 55.14375 287.397298 \nQ 55.14375 289.397298 57.14375 289.397298 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"PathCollection_6\">\n     <g>\n      <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.14375\" xlink:href=\"#m6663ee2562\" y=\"221.980111\"/>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- FoV -->\n     <g transform=\"translate(87.14375 224.605111)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 51.703125 72.90625 \nL 51.703125 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.109375 \nL 48.578125 43.109375 \nL 48.578125 34.8125 \nL 19.671875 34.8125 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-70\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 28.609375 0 \nL 0.78125 72.90625 \nL 11.078125 72.90625 \nL 34.1875 11.53125 \nL 57.328125 72.90625 \nL 67.578125 72.90625 \nL 39.796875 0 \nz\n\" id=\"DejaVuSans-86\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"53.894531\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"115.076172\" xlink:href=\"#DejaVuSans-86\"/>\n     </g>\n    </g>\n    <g id=\"PathCollection_7\">\n     <g>\n      <use style=\"fill:#ff7f0e;stroke:#ff7f0e;\" x=\"69.14375\" xlink:href=\"#m34d0ea9bc2\" y=\"236.658236\"/>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- All pixels -->\n     <g transform=\"translate(87.14375 239.283236)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n       <path id=\"DejaVuSans-32\"/>\n       <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"68.408203\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"96.191406\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"123.974609\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"155.761719\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"219.238281\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"247.021484\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"303.076172\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"364.599609\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"392.382812\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"PathCollection_8\">\n     <g>\n      <use style=\"fill:#2ca02c;stroke:#2ca02c;stroke-width:1.5;\" x=\"69.14375\" xlink:href=\"#ma1d09d7334\" y=\"251.336361\"/>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- Outlier -->\n     <g transform=\"translate(87.14375 253.961361)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 39.40625 66.21875 \nQ 28.65625 66.21875 22.328125 58.203125 \nQ 16.015625 50.203125 16.015625 36.375 \nQ 16.015625 22.609375 22.328125 14.59375 \nQ 28.65625 6.59375 39.40625 6.59375 \nQ 50.140625 6.59375 56.421875 14.59375 \nQ 62.703125 22.609375 62.703125 36.375 \nQ 62.703125 50.203125 56.421875 58.203125 \nQ 50.140625 66.21875 39.40625 66.21875 \nz\nM 39.40625 74.21875 \nQ 54.734375 74.21875 63.90625 63.9375 \nQ 73.09375 53.65625 73.09375 36.375 \nQ 73.09375 19.140625 63.90625 8.859375 \nQ 54.734375 -1.421875 39.40625 -1.421875 \nQ 24.03125 -1.421875 14.8125 8.828125 \nQ 5.609375 19.09375 5.609375 36.375 \nQ 5.609375 53.65625 14.8125 63.9375 \nQ 24.03125 74.21875 39.40625 74.21875 \nz\n\" id=\"DejaVuSans-79\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"78.710938\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"142.089844\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"181.298828\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"209.082031\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"236.865234\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"298.388672\" xlink:href=\"#DejaVuSans-114\"/>\n     </g>\n    </g>\n    <g id=\"PathCollection_9\">\n     <g>\n      <use style=\"fill:#d62728;stroke:#d62728;\" x=\"69.14375\" xlink:href=\"#md0a05cfca0\" y=\"266.014486\"/>\n     </g>\n    </g>\n    <g id=\"text_18\">\n     <!-- Ann. #2 with FoV -->\n     <g transform=\"translate(87.14375 268.639486)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n       <path d=\"M 51.125 44 \nL 36.921875 44 \nL 32.8125 27.6875 \nL 47.125 27.6875 \nz\nM 43.796875 71.78125 \nL 38.71875 51.515625 \nL 52.984375 51.515625 \nL 58.109375 71.78125 \nL 65.921875 71.78125 \nL 60.890625 51.515625 \nL 76.125 51.515625 \nL 76.125 44 \nL 58.984375 44 \nL 54.984375 27.6875 \nL 70.515625 27.6875 \nL 70.515625 20.21875 \nL 53.078125 20.21875 \nL 48 0 \nL 40.1875 0 \nL 45.21875 20.21875 \nL 30.90625 20.21875 \nL 25.875 0 \nL 18.015625 0 \nL 23.09375 20.21875 \nL 7.71875 20.21875 \nL 7.71875 27.6875 \nL 24.90625 27.6875 \nL 29 44 \nL 13.28125 44 \nL 13.28125 51.515625 \nL 30.90625 51.515625 \nL 35.890625 71.78125 \nz\n\" id=\"DejaVuSans-35\"/>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       <path d=\"M 4.203125 54.6875 \nL 13.1875 54.6875 \nL 24.421875 12.015625 \nL 35.59375 54.6875 \nL 46.1875 54.6875 \nL 57.421875 12.015625 \nL 68.609375 54.6875 \nL 77.59375 54.6875 \nL 63.28125 0 \nL 52.6875 0 \nL 40.921875 44.828125 \nL 29.109375 0 \nL 18.5 0 \nz\n\" id=\"DejaVuSans-119\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"68.408203\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"131.787109\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"195.166016\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"226.953125\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"258.740234\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"342.529297\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"406.152344\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"437.939453\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"519.726562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"547.509766\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"586.71875\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"650.097656\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"681.884766\" xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"735.779297\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"796.960938\" xlink:href=\"#DejaVuSans-86\"/>\n     </g>\n    </g>\n    <g id=\"PathCollection_10\">\n     <g>\n      <use style=\"fill:#9467bd;stroke:#9467bd;\" x=\"69.14375\" xlink:href=\"#m98aebe8425\" y=\"280.692611\"/>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- Ann. #2 with all pixels -->\n     <g transform=\"translate(87.14375 283.317611)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"68.408203\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"131.787109\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"195.166016\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"226.953125\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"258.740234\" xlink:href=\"#DejaVuSans-35\"/>\n      <use x=\"342.529297\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"406.152344\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"437.939453\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"519.726562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"547.509766\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"586.71875\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"650.097656\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"681.884766\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"743.164062\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"770.947266\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"798.730469\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"830.517578\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"893.994141\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"921.777344\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"977.832031\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1039.355469\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"1067.138672\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p556d2812f9\">\n   <rect height=\"285.998062\" width=\"295.15\" x=\"50.14375\" y=\"8.399236\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "markers= ['o', 's', '+', 'x']\n",
    "label_mapping= {'FoV': 'FoV', 'no FoV': 'All pixels', 'outlier': 'Outlier'}\n",
    "plt.figure(figsize=(5, 5))\n",
    "for i, c in enumerate(['FoV', 'no FoV', 'outlier']):\n",
    "    plt.scatter(reduced[reduced['category_agg'] == c]['acc'], reduced[reduced['category_agg'] == c]['spec'], label=label_mapping[c], marker=markers[i], s=100)\n",
    "plt.scatter([0.9473], [0.9725], label = 'Ann. #2 with FoV', marker='D', s=200)\n",
    "plt.scatter([0.9636], [0.9818], label = 'Ann. #2 with all pixels', marker='*', s=300)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Specificity')\n",
    "plt.gca().set_aspect(1.0)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(figures_dir, 'aggregated.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [key, flag, year, all_previous_processed, acc, sens, spec, digits, highest_ranked, second_human_observer, second_human_acc, second_human_sens, second_human_spec, image_level, short_description, operating_principles, citations, explicit_fov_usage, invalid_ranking, cause_of_invalid_ranking, image_level_consistency_with_fov, image_level_consistency_without_fov, n_image_level, category, n_aggregated_scores, consistency_with_fov_mor, consistency_without_fov_mor, consistency_with_fov_rom, consistency_without_fov_rom, consistency_with_fov, consistency_without_fov, category_agg]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>flag</th>\n      <th>year</th>\n      <th>all_previous_processed</th>\n      <th>acc</th>\n      <th>sens</th>\n      <th>spec</th>\n      <th>digits</th>\n      <th>highest_ranked</th>\n      <th>second_human_observer</th>\n      <th>...</th>\n      <th>n_image_level</th>\n      <th>category</th>\n      <th>n_aggregated_scores</th>\n      <th>consistency_with_fov_mor</th>\n      <th>consistency_without_fov_mor</th>\n      <th>consistency_with_fov_rom</th>\n      <th>consistency_without_fov_rom</th>\n      <th>consistency_with_fov</th>\n      <th>consistency_without_fov</th>\n      <th>category_agg</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows  32 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "reduced[reduced['category_agg'] == 'excluded']"
   ]
  },
  {
   "source": [
    "## Saving the results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods= pd.merge(methods.reset_index(drop=True), all[['key', 'category_agg']].reset_index(drop=True), on='key', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods['category_final']= methods['category'].where(methods['category'].notnull(), methods['category_agg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods.to_csv(aggregated_results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "np.sum(methods['invalid_ranking'] == 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        key     flag    year all_previous_processed     acc    sens    spec  digits           highest_ranked second_human_observer  ...  category  n_aggregated_scores  consistency_with_fov_mor consistency_without_fov_mor consistency_with_fov_rom consistency_without_fov_rom  consistency_with_fov consistency_without_fov category_agg category_final\n",
       "0                 adapa2020  primary  2020.0                    yes  0.9450  0.6994  0.9811     4.0            thangaraj2017                    no  ...       FoV                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "1                  alom2019  primary  2019.0                    yes  0.9613  0.7661  0.9807     4.0                 alom2019                    no  ...       NaN                  5.0                  0.600000                    0.200000                 0.400000                    0.000000                 False                   False      outlier        outlier\n",
       "2              anzalone2008  primary  2008.0                    yes  0.9418  0.7286  0.9810     4.0                    human                   yes  ...       NaN                  1.0                  0.000000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "3             azzopardi2014  primary  2014.0                    yes  0.9442  0.7655  0.9704     4.0                ricci2007                    no  ...       NaN                  3.0                  0.666667                    0.333333                 0.333333                    0.000000                  True                   False          FoV            FoV\n",
       "4               barkana2017  primary  2017.0                    yes  0.9502  0.7224  0.9840     4.0                 wang2015                   yes  ...   outlier                  4.0                  1.000000                    0.000000                 0.500000                    0.000000                  True                   False          FoV        outlier\n",
       "5              brancati2018  primary  2018.0                    yes  0.9490  0.7820  0.9760     3.0               frucci2017                   yes  ...       NaN                  5.0                  1.000000                    0.400000                 0.600000                    0.200000                  True                   False          FoV            FoV\n",
       "6                 budai2013  primary  2013.0                    yes  0.9570  0.6440  0.9870     3.0                budai2013                   yes  ...       NaN                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "7             chalakkal2017  primary  2017.0                    yes  0.9518  0.7386  0.9769     4.0              lupascu2010                    no  ...       NaN                  1.0                  0.000000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "8                 cheng2014  primary  2014.0                    yes  0.9474  0.7252  0.9798     4.0              lupascu2010                   yes  ...       NaN                  6.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "9                   dai2015  primary  2015.0                    yes  0.9418  0.7359  0.9720     4.0                  dai2015                    no  ...       NaN                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "10             dasgupta2017  primary  2017.0                    yes  0.9533  0.7691  0.9801     4.0             dasgupta2017                    no  ...       NaN                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "11                 dash2018  primary  2018.0                    yes  0.9570  0.7410  0.9860     3.0                 dash2018                    no  ...   outlier                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV        outlier\n",
       "12           dizdaroglu2012  primary  2012.0                    yes  0.9412  0.7181  0.9743     4.0                marin2011                    no  ...       NaN                  2.0                  0.500000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "13                emary2014  primary  2014.0                    yes  0.9390  0.7210  0.9710     3.0             mendonca2006                    no  ...       FoV                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "14   escorcia-gutierrez2020  primary  2020.0                    yes  0.9640  0.6170  0.9980     3.0            jebaseeli2019                    no  ...   outlier                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV        outlier\n",
       "15                  fan2017  primary  2017.0                    yes  0.9600  0.7360  0.9810     3.0                  fan2017                    no  ...       NaN                  2.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "16                fathi2013  primary  2013.0                    yes  0.9581  0.7768  0.9759     4.0                ricci2007                    no  ...    no FoV                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV         no FoV\n",
       "17                 fraz2012  primary  2012.0                    yes  0.9430  0.7152  0.9769     4.0                ricci2007                   yes  ...   outlier                 11.0                  0.909091                    0.000000                 0.000000                    0.000000                  True                   False          FoV        outlier\n",
       "18                fraz2012b  primary  2012.0                    yes  0.9480  0.7406  0.9807     4.0              lupascu2010                   yes  ...   outlier                  3.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV        outlier\n",
       "19               frucci2016  primary  2016.0                    yes  0.9550  0.6400  0.9850     3.0                ricci2007                    no  ...    no FoV                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "20               frucci2017  primary  2017.0                    yes  0.9560  0.6600  0.9850     3.0               frucci2017                    no  ...       NaN                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "21         geetharamani2016  primary  2016.0                    yes  0.9536  0.7079  0.9778     4.0         geetharamani2016                   yes  ...    no FoV                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV         no FoV\n",
       "22               hassan2018  primary  2018.0                    yes  0.9793  0.8981  0.9883     4.0               hassan2018                    no  ...   outlier                  1.0                  1.000000                    1.000000                 0.000000                    0.000000                  True                    True    ambiguous        outlier\n",
       "23                   hu2018  primary  2018.0                    yes  0.9533  0.7796  0.9717     4.0                  zhu2016                   yes  ...       NaN                  4.0                  0.750000                    0.250000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "24                imani2015  primary  2015.0                    yes  0.9523  0.7524  0.9753     4.0                imani2015                   yes  ...   outlier                  5.0                  0.000000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "25               javidi2017  primary  2017.0                    yes  0.9450  0.7201  0.9702     4.0                imani2015                   yes  ...       NaN                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV         no FoV\n",
       "26            jebaseeli2019  primary  2019.0                    yes  0.9898  0.8027  0.9980     4.0            jebaseeli2019                    no  ...       NaN                  1.0                  0.000000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "27                jiang2019  primary  2019.0                    yes  0.9706  0.8325  0.9838     4.0                jiang2019                   yes  ...       NaN                  9.0                  0.111111                    0.888889                 0.111111                    0.888889                 False                    True       no FoV         no FoV\n",
       "28                 kaur2017  primary  2017.0                    yes  0.9480  0.8730  0.9869     4.0                 zhao2015                    no  ...       NaN                  1.0                  0.000000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "29                 khan2016  primary  2016.0                    yes  0.9501  0.7373  0.9670     4.0                 khan2016                   yes  ...   outlier                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV        outlier\n",
       "30               kovacs2016  primary  2016.0                    yes  0.9494  0.7450  0.9793     4.0               kovacs2016                   yes  ...       NaN                  2.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "31                kumar2016  primary  2016.0                    yes  0.9626  0.7006  0.9871     4.0                kumar2016                    no  ...       NaN                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV         no FoV\n",
       "32                   li2016  primary  2016.0                    yes  0.9527  0.7569  0.9816     4.0              lupascu2010                   yes  ...       FoV                  2.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "33            liskowski2016  primary  2016.0                    yes  0.9535  0.7811  0.9807     4.0  villalobos-castaldi2010                   yes  ...       NaN                 12.0                  0.916667                    0.083333                 0.083333                    0.000000                  True                   False          FoV            FoV\n",
       "34              lupascu2010  primary  2010.0                    yes  0.9597  0.6728  0.9874     4.0              lupascu2010                   yes  ...    no FoV                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "35               mapayi2015  primary  2015.0                    yes  0.9511  0.7313  0.9724     4.0                ricci2007                   yes  ...       NaN                  6.0                  0.000000                    1.000000                 0.000000                    0.666667                 False                    True       no FoV         no FoV\n",
       "36                marin2011  primary  2011.0                    yes  0.9452  0.7067  0.9801     4.0                ricci2007                    no  ...       FoV                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "37            melinscak2015  primary  2015.0                    yes  0.9466  0.7276  0.9785     4.0                        -                    no  ...       NaN                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "38               memari2017  primary  2017.0                    yes  0.9722  0.8726  0.9884     4.0               memari2017                   yes  ...       NaN                  2.0                  0.500000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "39             mendonca2006  primary  2006.0                    yes  0.9463  0.7315  0.9781     4.0                    human                   yes  ...       NaN                  2.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "40                 meng2015  primary  2015.0                    yes  0.9529  0.7489  0.9818     4.0              lupascu2010                   yes  ...   outlier                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV        outlier\n",
       "41                 miri2011  primary  2011.0                    yes  0.9458  0.7352  0.9795     4.0                 miri2011                    no  ...       NaN                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "42                   mo2017  primary  2017.0                    yes  0.9521  0.7760  0.9779     4.0              lupascu2010                    no  ...       FoV                  2.0                  1.000000                    0.000000                 0.500000                    0.000000                  True                   False          FoV            FoV\n",
       "43           moghimirad2012  primary  2012.0                    yes  0.9659  0.7852  0.9935     4.0           moghimirad2012                   yes  ...   outlier                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV        outlier\n",
       "44               nazari2013  primary  2013.0                    yes  0.9481  0.7112  0.9716     4.0               nazari2013                   yes  ...       NaN                  2.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV         no FoV\n",
       "45                  ngo2017  primary  2017.0                    yes  0.9533  0.7464  0.9836     4.0                 wang2015                    no  ...       NaN                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "46                  noh2019  primary  2019.0                     no  0.9569  0.8354  0.9746     4.0                  noh2019                   yes  ...       NaN                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "47           odstrcilik2013  primary  2013.0                    yes  0.9340  0.7060  0.9693     4.0              lupascu2010                   yes  ...   outlier                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV        outlier\n",
       "48            palanivel2020  primary  2020.0                     no  0.9480  0.7375  0.9788     4.0               memari2017                   yes  ...       NaN                  4.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "49                  pan2019  primary  2019.0                    yes  0.9650  0.8150  0.9808     4.0                liang2019                    no  ...       NaN                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV         no FoV\n",
       "50                panda2016  primary  2016.0                    yes  0.9539  0.7328  0.9752     4.0              lupascu2010                   yes  ...       NaN                  4.0                  0.000000                    1.000000                 0.000000                    0.500000                 False                    True       no FoV         no FoV\n",
       "51               pandey2016  primary  2016.0                    yes  0.9623  0.8106  0.9761     4.0               pandey2016                    no  ...       NaN                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV         no FoV\n",
       "52                 park2020  primary  2020.0                    yes  0.9706  0.8346  0.9836     4.0                 park2020                    no  ...       NaN                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "53               rahebi2014  primary  2014.0                    yes  0.9461  0.7365  0.9707     4.0  villalobos-castaldi2010                    no  ...   outlier                  1.0                  0.000000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "54               rezaee2017  primary  2017.0                    yes  0.9463  0.7189  0.9793     4.0                ricci2007                   yes  ...       NaN                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "55                ricci2007  primary  2007.0                    yes  0.9595  0.7283  0.9832     4.0                ricci2007                   yes  ...   outlier                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV        outlier\n",
       "56         roychowdhury2015  primary  2015.0                    yes  0.9494  0.7395  0.9782     4.0                ricci2007                    no  ...       NaN                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "57     salazar-gonzalez2014  primary  2014.0                    yes  0.9412  0.7512  0.9684     4.0                ricci2007                   yes  ...       NaN                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "58                saleh2011  primary  2011.0                    yes  0.9630  0.8423  0.9658     4.0                saleh2011                   yes  ...       NaN                  2.0                  0.500000                    0.500000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "59               samuel2019  primary  2019.0                    yes  0.9609  0.8282  0.9738     4.0               samuel2019                   yes  ...       NaN                  4.0                  0.250000                    1.000000                 0.000000                    0.500000                 False                    True       no FoV         no FoV\n",
       "60                saroj2020  primary  2020.0                    yes  0.9544  0.7307  0.9761     4.0                saroj2020                    no  ...    no FoV                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV         no FoV\n",
       "61                 shah2017  primary  2017.0                    yes  0.9479  0.7205  0.9814     4.0                 zhao2015                   yes  ...       NaN                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "62               shukla2020  primary  2020.0                     no  0.9476  0.7015  0.9836     4.0            thangaraj2017                   yes  ...       NaN                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "63                singh2016  primary  2016.0                    yes  0.9522  0.7594  0.9708     4.0                singh2016                    no  ...    no FoV                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "64                singh2017  primary  2017.0                    yes  0.9513  0.7171  0.9739     4.0                singh2017                    no  ...    no FoV                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "65                 song2017  primary  2017.0                    yes  0.9499  0.7501  0.9795     4.0                 zhao2015                   yes  ...       NaN                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "66               soomro2017  primary  2017.0                    yes  0.9432  0.7523  0.9760     4.0              lupascu2010                    no  ...       NaN                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "67               soomro2018  primary  2018.0                    yes  0.9534  0.7592  0.9763     4.0              lupascu2010                    no  ...       NaN                  4.0                  0.500000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "68               soomro2019  primary  2019.0                    yes  0.9560  0.8700  0.9850     3.0               soomro2019                    no  ...       NaN                  1.0                  0.000000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "69             sreejini2015  primary  2015.0                    yes  0.9633  0.7132  0.9866     4.0             sreejini2015                   yes  ...       NaN                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV         no FoV\n",
       "70                staal2004  primary  2004.0                    yes  0.9441  0.7750  0.9725     4.0                    human                   yes  ...       NaN                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "71         strisciuglio2015  primary  2015.0                    yes  0.9442  0.7655  0.9704     4.0         strisciuglio2015                    no  ...       NaN                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "72         strisciuglio2016  primary  2016.0                    yes  0.9454  0.7777  0.9702     4.0                ricci2007                    no  ...       NaN                  5.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "73                tamim2020  primary  2020.0                     no  0.9607  0.7542  0.9843     4.0                tamim2020                    no  ...   outlier                  1.0                  0.000000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "74                 tang2017  primary  2017.0                    yes  0.9611  0.8174  0.9747     4.0                 tang2017                   yes  ...   outlier                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV        outlier\n",
       "75            thangaraj2017  primary  2017.0                    yes  0.9606  0.8014  0.9753     4.0            thangaraj2017                    no  ...   outlier                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV        outlier\n",
       "76  villalobos-castaldi2010  primary  2010.0                    yes  0.9759  0.9649  0.9480     4.0  villalobos-castaldi2010                   yes  ...       NaN                  1.0                  0.000000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "77               waheed2015  primary  2015.0                    yes  0.9616  0.7937  0.9779     4.0               waheed2015                    no  ...    no FoV                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "78                 wang2015  primary  2015.0                    yes  0.9767  0.8173  0.9733     4.0                 wang2015                   yes  ...   outlier                  9.0                  0.000000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "79             wankhede2015  primary  2015.0                    yes  0.9626  0.7261  0.9806     4.0             wankhede2015                   yes  ...       NaN                  1.0                  0.000000                    0.000000                 0.000000                    0.000000                 False                   False      outlier        outlier\n",
       "80                   wu2020  primary  2020.0                     no  0.9582  0.7996  0.9813     4.0                   wu2020                    no  ...       NaN                  3.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "81                xiang2014  primary  2014.0                    yes  0.9613  0.7538  0.9828     4.0                xiang2014                   yes  ...       NaN                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV         no FoV\n",
       "82                  yan2018  primary  2018.0                    yes  0.9542  0.7653  0.9818     4.0                  yan2018                   yes  ...       NaN                  2.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "83                 yang2020  primary  2020.0                     no  0.9532  0.7349  0.9743     4.0                 yang2020                    no  ...       NaN                  4.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "84                  you2011  primary  2011.0                    yes  0.9434  0.7410  0.9751     4.0                    human                   yes  ...       NaN                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "85                zhang2010  primary  2010.0                    yes  0.9382  0.7120  0.9724     4.0              al-rawi2007                   yes  ...       NaN                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "86                zhang2016  primary  2016.0                    yes  0.9476  0.7743  0.9725     4.0              lupascu2010                   yes  ...       NaN                  2.0                  1.000000                    0.000000                 0.500000                    0.000000                  True                   False          FoV            FoV\n",
       "87                zhang2018  primary  2018.0                    yes  0.9504  0.8723  0.9618     4.0            liskowski2016                   yes  ...       NaN                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV            FoV\n",
       "88                 zhao2015  primary  2015.0                    yes  0.9540  0.7420  0.9820     3.0              lupascu2010                   yes  ...       NaN                  5.0                  0.400000                    0.400000                 0.200000                    0.400000                 False                   False      outlier        outlier\n",
       "89                zhao2015b  primary  2015.0                    yes  0.9530  0.7440  0.9780     3.0                zhao2015b                   yes  ...       NaN                 10.0                  0.400000                    0.500000                 0.000000                    0.100000                 False                   False      outlier        outlier\n",
       "90                 zhou2017  primary  2017.0                    yes  0.9469  0.8078  0.9674     4.0                 wang2015                   yes  ...       NaN                  4.0                  1.000000                    0.000000                 0.750000                    0.000000                  True                   False          FoV            FoV\n",
       "91                  zhu2016  primary  2016.0                    yes  0.9607  0.7140  0.9868     4.0                 wang2015                    no  ...   outlier                  9.0                  0.000000                    0.888889                 0.000000                    0.000000                 False                    True       no FoV        outlier\n",
       "92                 dash2020  primary  2020.0                    yes  0.9520  0.7560  0.9810     3.0                budai2013                    no  ...   outlier                  1.0                  1.000000                    0.000000                 1.000000                    0.000000                  True                   False          FoV        outlier\n",
       "93                   na2018  primary  2018.0                    yes  0.9540  0.7680  0.9700     3.0              lupascu2010                   yes  ...       NaN                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "94              bharkad2017  primary  2017.0                    yes  0.9503  0.7278  0.9718     4.0              bharkad2017                    no  ...    no FoV                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "95              lupascu2016  primary  2016.0                    yes  0.9606  0.7006  0.9857     4.0              lupascu2016                   yes  ...    no FoV                  2.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "96                kumar2020  primary  2020.0                    NaN  0.9432  0.7503  0.9717     4.0                ricci2007                   yes  ...       FoV                  1.0                  1.000000                    0.000000                 0.000000                    0.000000                  True                   False          FoV            FoV\n",
       "97              rahmani2020  primary  2020.0                    NaN  0.9521  0.7400  0.9726     4.0              rahmani2020                    no  ...       NaN                  1.0                  0.000000                    1.000000                 0.000000                    1.000000                 False                    True       no FoV         no FoV\n",
       "98                 atli2020  primary  2020.0                    yes  0.9689  0.7987  0.9854     4.0                 wang2015                   yes  ...       NaN                  2.0                  0.000000                    0.500000                 0.000000                    0.500000                 False                   False      outlier        outlier\n",
       "99           narkthewan2019  primary  2019.0                    yes  0.9617  0.6392  0.9920     4.0                      NaN                    no  ...   outlier                  1.0                  0.000000                    1.000000                 0.000000                    0.000000                 False                    True       no FoV        outlier\n",
       "\n",
       "[100 rows x 33 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>flag</th>\n      <th>year</th>\n      <th>all_previous_processed</th>\n      <th>acc</th>\n      <th>sens</th>\n      <th>spec</th>\n      <th>digits</th>\n      <th>highest_ranked</th>\n      <th>second_human_observer</th>\n      <th>...</th>\n      <th>category</th>\n      <th>n_aggregated_scores</th>\n      <th>consistency_with_fov_mor</th>\n      <th>consistency_without_fov_mor</th>\n      <th>consistency_with_fov_rom</th>\n      <th>consistency_without_fov_rom</th>\n      <th>consistency_with_fov</th>\n      <th>consistency_without_fov</th>\n      <th>category_agg</th>\n      <th>category_final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>adapa2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>yes</td>\n      <td>0.9450</td>\n      <td>0.6994</td>\n      <td>0.9811</td>\n      <td>4.0</td>\n      <td>thangaraj2017</td>\n      <td>no</td>\n      <td>...</td>\n      <td>FoV</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>alom2019</td>\n      <td>primary</td>\n      <td>2019.0</td>\n      <td>yes</td>\n      <td>0.9613</td>\n      <td>0.7661</td>\n      <td>0.9807</td>\n      <td>4.0</td>\n      <td>alom2019</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>0.600000</td>\n      <td>0.200000</td>\n      <td>0.400000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>anzalone2008</td>\n      <td>primary</td>\n      <td>2008.0</td>\n      <td>yes</td>\n      <td>0.9418</td>\n      <td>0.7286</td>\n      <td>0.9810</td>\n      <td>4.0</td>\n      <td>human</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>azzopardi2014</td>\n      <td>primary</td>\n      <td>2014.0</td>\n      <td>yes</td>\n      <td>0.9442</td>\n      <td>0.7655</td>\n      <td>0.9704</td>\n      <td>4.0</td>\n      <td>ricci2007</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>0.666667</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>barkana2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9502</td>\n      <td>0.7224</td>\n      <td>0.9840</td>\n      <td>4.0</td>\n      <td>wang2015</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>4.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>brancati2018</td>\n      <td>primary</td>\n      <td>2018.0</td>\n      <td>yes</td>\n      <td>0.9490</td>\n      <td>0.7820</td>\n      <td>0.9760</td>\n      <td>3.0</td>\n      <td>frucci2017</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.000000</td>\n      <td>0.400000</td>\n      <td>0.600000</td>\n      <td>0.200000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>budai2013</td>\n      <td>primary</td>\n      <td>2013.0</td>\n      <td>yes</td>\n      <td>0.9570</td>\n      <td>0.6440</td>\n      <td>0.9870</td>\n      <td>3.0</td>\n      <td>budai2013</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>chalakkal2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9518</td>\n      <td>0.7386</td>\n      <td>0.9769</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>cheng2014</td>\n      <td>primary</td>\n      <td>2014.0</td>\n      <td>yes</td>\n      <td>0.9474</td>\n      <td>0.7252</td>\n      <td>0.9798</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>dai2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9418</td>\n      <td>0.7359</td>\n      <td>0.9720</td>\n      <td>4.0</td>\n      <td>dai2015</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>dasgupta2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9533</td>\n      <td>0.7691</td>\n      <td>0.9801</td>\n      <td>4.0</td>\n      <td>dasgupta2017</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>dash2018</td>\n      <td>primary</td>\n      <td>2018.0</td>\n      <td>yes</td>\n      <td>0.9570</td>\n      <td>0.7410</td>\n      <td>0.9860</td>\n      <td>3.0</td>\n      <td>dash2018</td>\n      <td>no</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>dizdaroglu2012</td>\n      <td>primary</td>\n      <td>2012.0</td>\n      <td>yes</td>\n      <td>0.9412</td>\n      <td>0.7181</td>\n      <td>0.9743</td>\n      <td>4.0</td>\n      <td>marin2011</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>emary2014</td>\n      <td>primary</td>\n      <td>2014.0</td>\n      <td>yes</td>\n      <td>0.9390</td>\n      <td>0.7210</td>\n      <td>0.9710</td>\n      <td>3.0</td>\n      <td>mendonca2006</td>\n      <td>no</td>\n      <td>...</td>\n      <td>FoV</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>escorcia-gutierrez2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>yes</td>\n      <td>0.9640</td>\n      <td>0.6170</td>\n      <td>0.9980</td>\n      <td>3.0</td>\n      <td>jebaseeli2019</td>\n      <td>no</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>fan2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9600</td>\n      <td>0.7360</td>\n      <td>0.9810</td>\n      <td>3.0</td>\n      <td>fan2017</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>fathi2013</td>\n      <td>primary</td>\n      <td>2013.0</td>\n      <td>yes</td>\n      <td>0.9581</td>\n      <td>0.7768</td>\n      <td>0.9759</td>\n      <td>4.0</td>\n      <td>ricci2007</td>\n      <td>no</td>\n      <td>...</td>\n      <td>no FoV</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>fraz2012</td>\n      <td>primary</td>\n      <td>2012.0</td>\n      <td>yes</td>\n      <td>0.9430</td>\n      <td>0.7152</td>\n      <td>0.9769</td>\n      <td>4.0</td>\n      <td>ricci2007</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>11.0</td>\n      <td>0.909091</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>fraz2012b</td>\n      <td>primary</td>\n      <td>2012.0</td>\n      <td>yes</td>\n      <td>0.9480</td>\n      <td>0.7406</td>\n      <td>0.9807</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>3.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>frucci2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9550</td>\n      <td>0.6400</td>\n      <td>0.9850</td>\n      <td>3.0</td>\n      <td>ricci2007</td>\n      <td>no</td>\n      <td>...</td>\n      <td>no FoV</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>frucci2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9560</td>\n      <td>0.6600</td>\n      <td>0.9850</td>\n      <td>3.0</td>\n      <td>frucci2017</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>geetharamani2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9536</td>\n      <td>0.7079</td>\n      <td>0.9778</td>\n      <td>4.0</td>\n      <td>geetharamani2016</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>no FoV</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>hassan2018</td>\n      <td>primary</td>\n      <td>2018.0</td>\n      <td>yes</td>\n      <td>0.9793</td>\n      <td>0.8981</td>\n      <td>0.9883</td>\n      <td>4.0</td>\n      <td>hassan2018</td>\n      <td>no</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>True</td>\n      <td>ambiguous</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>hu2018</td>\n      <td>primary</td>\n      <td>2018.0</td>\n      <td>yes</td>\n      <td>0.9533</td>\n      <td>0.7796</td>\n      <td>0.9717</td>\n      <td>4.0</td>\n      <td>zhu2016</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>0.750000</td>\n      <td>0.250000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>imani2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9523</td>\n      <td>0.7524</td>\n      <td>0.9753</td>\n      <td>4.0</td>\n      <td>imani2015</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>5.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>javidi2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9450</td>\n      <td>0.7201</td>\n      <td>0.9702</td>\n      <td>4.0</td>\n      <td>imani2015</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>jebaseeli2019</td>\n      <td>primary</td>\n      <td>2019.0</td>\n      <td>yes</td>\n      <td>0.9898</td>\n      <td>0.8027</td>\n      <td>0.9980</td>\n      <td>4.0</td>\n      <td>jebaseeli2019</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>jiang2019</td>\n      <td>primary</td>\n      <td>2019.0</td>\n      <td>yes</td>\n      <td>0.9706</td>\n      <td>0.8325</td>\n      <td>0.9838</td>\n      <td>4.0</td>\n      <td>jiang2019</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>0.111111</td>\n      <td>0.888889</td>\n      <td>0.111111</td>\n      <td>0.888889</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>kaur2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9480</td>\n      <td>0.8730</td>\n      <td>0.9869</td>\n      <td>4.0</td>\n      <td>zhao2015</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>khan2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9501</td>\n      <td>0.7373</td>\n      <td>0.9670</td>\n      <td>4.0</td>\n      <td>khan2016</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>kovacs2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9494</td>\n      <td>0.7450</td>\n      <td>0.9793</td>\n      <td>4.0</td>\n      <td>kovacs2016</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>kumar2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9626</td>\n      <td>0.7006</td>\n      <td>0.9871</td>\n      <td>4.0</td>\n      <td>kumar2016</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>li2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9527</td>\n      <td>0.7569</td>\n      <td>0.9816</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>FoV</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>liskowski2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9535</td>\n      <td>0.7811</td>\n      <td>0.9807</td>\n      <td>4.0</td>\n      <td>villalobos-castaldi2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>0.916667</td>\n      <td>0.083333</td>\n      <td>0.083333</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>lupascu2010</td>\n      <td>primary</td>\n      <td>2010.0</td>\n      <td>yes</td>\n      <td>0.9597</td>\n      <td>0.6728</td>\n      <td>0.9874</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>no FoV</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>mapayi2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9511</td>\n      <td>0.7313</td>\n      <td>0.9724</td>\n      <td>4.0</td>\n      <td>ricci2007</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>marin2011</td>\n      <td>primary</td>\n      <td>2011.0</td>\n      <td>yes</td>\n      <td>0.9452</td>\n      <td>0.7067</td>\n      <td>0.9801</td>\n      <td>4.0</td>\n      <td>ricci2007</td>\n      <td>no</td>\n      <td>...</td>\n      <td>FoV</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>melinscak2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9466</td>\n      <td>0.7276</td>\n      <td>0.9785</td>\n      <td>4.0</td>\n      <td>-</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>memari2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9722</td>\n      <td>0.8726</td>\n      <td>0.9884</td>\n      <td>4.0</td>\n      <td>memari2017</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>mendonca2006</td>\n      <td>primary</td>\n      <td>2006.0</td>\n      <td>yes</td>\n      <td>0.9463</td>\n      <td>0.7315</td>\n      <td>0.9781</td>\n      <td>4.0</td>\n      <td>human</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>meng2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9529</td>\n      <td>0.7489</td>\n      <td>0.9818</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>miri2011</td>\n      <td>primary</td>\n      <td>2011.0</td>\n      <td>yes</td>\n      <td>0.9458</td>\n      <td>0.7352</td>\n      <td>0.9795</td>\n      <td>4.0</td>\n      <td>miri2011</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>mo2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9521</td>\n      <td>0.7760</td>\n      <td>0.9779</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>no</td>\n      <td>...</td>\n      <td>FoV</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>moghimirad2012</td>\n      <td>primary</td>\n      <td>2012.0</td>\n      <td>yes</td>\n      <td>0.9659</td>\n      <td>0.7852</td>\n      <td>0.9935</td>\n      <td>4.0</td>\n      <td>moghimirad2012</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>nazari2013</td>\n      <td>primary</td>\n      <td>2013.0</td>\n      <td>yes</td>\n      <td>0.9481</td>\n      <td>0.7112</td>\n      <td>0.9716</td>\n      <td>4.0</td>\n      <td>nazari2013</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>ngo2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9533</td>\n      <td>0.7464</td>\n      <td>0.9836</td>\n      <td>4.0</td>\n      <td>wang2015</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>noh2019</td>\n      <td>primary</td>\n      <td>2019.0</td>\n      <td>no</td>\n      <td>0.9569</td>\n      <td>0.8354</td>\n      <td>0.9746</td>\n      <td>4.0</td>\n      <td>noh2019</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>odstrcilik2013</td>\n      <td>primary</td>\n      <td>2013.0</td>\n      <td>yes</td>\n      <td>0.9340</td>\n      <td>0.7060</td>\n      <td>0.9693</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>palanivel2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>no</td>\n      <td>0.9480</td>\n      <td>0.7375</td>\n      <td>0.9788</td>\n      <td>4.0</td>\n      <td>memari2017</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>pan2019</td>\n      <td>primary</td>\n      <td>2019.0</td>\n      <td>yes</td>\n      <td>0.9650</td>\n      <td>0.8150</td>\n      <td>0.9808</td>\n      <td>4.0</td>\n      <td>liang2019</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>panda2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9539</td>\n      <td>0.7328</td>\n      <td>0.9752</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>pandey2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9623</td>\n      <td>0.8106</td>\n      <td>0.9761</td>\n      <td>4.0</td>\n      <td>pandey2016</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>park2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>yes</td>\n      <td>0.9706</td>\n      <td>0.8346</td>\n      <td>0.9836</td>\n      <td>4.0</td>\n      <td>park2020</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>rahebi2014</td>\n      <td>primary</td>\n      <td>2014.0</td>\n      <td>yes</td>\n      <td>0.9461</td>\n      <td>0.7365</td>\n      <td>0.9707</td>\n      <td>4.0</td>\n      <td>villalobos-castaldi2010</td>\n      <td>no</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>rezaee2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9463</td>\n      <td>0.7189</td>\n      <td>0.9793</td>\n      <td>4.0</td>\n      <td>ricci2007</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>ricci2007</td>\n      <td>primary</td>\n      <td>2007.0</td>\n      <td>yes</td>\n      <td>0.9595</td>\n      <td>0.7283</td>\n      <td>0.9832</td>\n      <td>4.0</td>\n      <td>ricci2007</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>roychowdhury2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9494</td>\n      <td>0.7395</td>\n      <td>0.9782</td>\n      <td>4.0</td>\n      <td>ricci2007</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>salazar-gonzalez2014</td>\n      <td>primary</td>\n      <td>2014.0</td>\n      <td>yes</td>\n      <td>0.9412</td>\n      <td>0.7512</td>\n      <td>0.9684</td>\n      <td>4.0</td>\n      <td>ricci2007</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>saleh2011</td>\n      <td>primary</td>\n      <td>2011.0</td>\n      <td>yes</td>\n      <td>0.9630</td>\n      <td>0.8423</td>\n      <td>0.9658</td>\n      <td>4.0</td>\n      <td>saleh2011</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>samuel2019</td>\n      <td>primary</td>\n      <td>2019.0</td>\n      <td>yes</td>\n      <td>0.9609</td>\n      <td>0.8282</td>\n      <td>0.9738</td>\n      <td>4.0</td>\n      <td>samuel2019</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>0.250000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>saroj2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>yes</td>\n      <td>0.9544</td>\n      <td>0.7307</td>\n      <td>0.9761</td>\n      <td>4.0</td>\n      <td>saroj2020</td>\n      <td>no</td>\n      <td>...</td>\n      <td>no FoV</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>shah2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9479</td>\n      <td>0.7205</td>\n      <td>0.9814</td>\n      <td>4.0</td>\n      <td>zhao2015</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>shukla2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>no</td>\n      <td>0.9476</td>\n      <td>0.7015</td>\n      <td>0.9836</td>\n      <td>4.0</td>\n      <td>thangaraj2017</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>singh2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9522</td>\n      <td>0.7594</td>\n      <td>0.9708</td>\n      <td>4.0</td>\n      <td>singh2016</td>\n      <td>no</td>\n      <td>...</td>\n      <td>no FoV</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>singh2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9513</td>\n      <td>0.7171</td>\n      <td>0.9739</td>\n      <td>4.0</td>\n      <td>singh2017</td>\n      <td>no</td>\n      <td>...</td>\n      <td>no FoV</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>song2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9499</td>\n      <td>0.7501</td>\n      <td>0.9795</td>\n      <td>4.0</td>\n      <td>zhao2015</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>soomro2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9432</td>\n      <td>0.7523</td>\n      <td>0.9760</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>soomro2018</td>\n      <td>primary</td>\n      <td>2018.0</td>\n      <td>yes</td>\n      <td>0.9534</td>\n      <td>0.7592</td>\n      <td>0.9763</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>soomro2019</td>\n      <td>primary</td>\n      <td>2019.0</td>\n      <td>yes</td>\n      <td>0.9560</td>\n      <td>0.8700</td>\n      <td>0.9850</td>\n      <td>3.0</td>\n      <td>soomro2019</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>sreejini2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9633</td>\n      <td>0.7132</td>\n      <td>0.9866</td>\n      <td>4.0</td>\n      <td>sreejini2015</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>staal2004</td>\n      <td>primary</td>\n      <td>2004.0</td>\n      <td>yes</td>\n      <td>0.9441</td>\n      <td>0.7750</td>\n      <td>0.9725</td>\n      <td>4.0</td>\n      <td>human</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>strisciuglio2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9442</td>\n      <td>0.7655</td>\n      <td>0.9704</td>\n      <td>4.0</td>\n      <td>strisciuglio2015</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>strisciuglio2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9454</td>\n      <td>0.7777</td>\n      <td>0.9702</td>\n      <td>4.0</td>\n      <td>ricci2007</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>tamim2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>no</td>\n      <td>0.9607</td>\n      <td>0.7542</td>\n      <td>0.9843</td>\n      <td>4.0</td>\n      <td>tamim2020</td>\n      <td>no</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>tang2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9611</td>\n      <td>0.8174</td>\n      <td>0.9747</td>\n      <td>4.0</td>\n      <td>tang2017</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>thangaraj2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9606</td>\n      <td>0.8014</td>\n      <td>0.9753</td>\n      <td>4.0</td>\n      <td>thangaraj2017</td>\n      <td>no</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>villalobos-castaldi2010</td>\n      <td>primary</td>\n      <td>2010.0</td>\n      <td>yes</td>\n      <td>0.9759</td>\n      <td>0.9649</td>\n      <td>0.9480</td>\n      <td>4.0</td>\n      <td>villalobos-castaldi2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>waheed2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9616</td>\n      <td>0.7937</td>\n      <td>0.9779</td>\n      <td>4.0</td>\n      <td>waheed2015</td>\n      <td>no</td>\n      <td>...</td>\n      <td>no FoV</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>wang2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9767</td>\n      <td>0.8173</td>\n      <td>0.9733</td>\n      <td>4.0</td>\n      <td>wang2015</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>9.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>wankhede2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9626</td>\n      <td>0.7261</td>\n      <td>0.9806</td>\n      <td>4.0</td>\n      <td>wankhede2015</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>wu2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>no</td>\n      <td>0.9582</td>\n      <td>0.7996</td>\n      <td>0.9813</td>\n      <td>4.0</td>\n      <td>wu2020</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>xiang2014</td>\n      <td>primary</td>\n      <td>2014.0</td>\n      <td>yes</td>\n      <td>0.9613</td>\n      <td>0.7538</td>\n      <td>0.9828</td>\n      <td>4.0</td>\n      <td>xiang2014</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>yan2018</td>\n      <td>primary</td>\n      <td>2018.0</td>\n      <td>yes</td>\n      <td>0.9542</td>\n      <td>0.7653</td>\n      <td>0.9818</td>\n      <td>4.0</td>\n      <td>yan2018</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>yang2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>no</td>\n      <td>0.9532</td>\n      <td>0.7349</td>\n      <td>0.9743</td>\n      <td>4.0</td>\n      <td>yang2020</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>you2011</td>\n      <td>primary</td>\n      <td>2011.0</td>\n      <td>yes</td>\n      <td>0.9434</td>\n      <td>0.7410</td>\n      <td>0.9751</td>\n      <td>4.0</td>\n      <td>human</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>zhang2010</td>\n      <td>primary</td>\n      <td>2010.0</td>\n      <td>yes</td>\n      <td>0.9382</td>\n      <td>0.7120</td>\n      <td>0.9724</td>\n      <td>4.0</td>\n      <td>al-rawi2007</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>zhang2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9476</td>\n      <td>0.7743</td>\n      <td>0.9725</td>\n      <td>4.0</td>\n      <td>lupascu2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>zhang2018</td>\n      <td>primary</td>\n      <td>2018.0</td>\n      <td>yes</td>\n      <td>0.9504</td>\n      <td>0.8723</td>\n      <td>0.9618</td>\n      <td>4.0</td>\n      <td>liskowski2016</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>zhao2015</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9540</td>\n      <td>0.7420</td>\n      <td>0.9820</td>\n      <td>3.0</td>\n      <td>lupascu2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>0.400000</td>\n      <td>0.400000</td>\n      <td>0.200000</td>\n      <td>0.400000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>zhao2015b</td>\n      <td>primary</td>\n      <td>2015.0</td>\n      <td>yes</td>\n      <td>0.9530</td>\n      <td>0.7440</td>\n      <td>0.9780</td>\n      <td>3.0</td>\n      <td>zhao2015b</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>0.400000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.100000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>zhou2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9469</td>\n      <td>0.8078</td>\n      <td>0.9674</td>\n      <td>4.0</td>\n      <td>wang2015</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.750000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>zhu2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9607</td>\n      <td>0.7140</td>\n      <td>0.9868</td>\n      <td>4.0</td>\n      <td>wang2015</td>\n      <td>no</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>9.0</td>\n      <td>0.000000</td>\n      <td>0.888889</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>dash2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>yes</td>\n      <td>0.9520</td>\n      <td>0.7560</td>\n      <td>0.9810</td>\n      <td>3.0</td>\n      <td>budai2013</td>\n      <td>no</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>na2018</td>\n      <td>primary</td>\n      <td>2018.0</td>\n      <td>yes</td>\n      <td>0.9540</td>\n      <td>0.7680</td>\n      <td>0.9700</td>\n      <td>3.0</td>\n      <td>lupascu2010</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>bharkad2017</td>\n      <td>primary</td>\n      <td>2017.0</td>\n      <td>yes</td>\n      <td>0.9503</td>\n      <td>0.7278</td>\n      <td>0.9718</td>\n      <td>4.0</td>\n      <td>bharkad2017</td>\n      <td>no</td>\n      <td>...</td>\n      <td>no FoV</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>lupascu2016</td>\n      <td>primary</td>\n      <td>2016.0</td>\n      <td>yes</td>\n      <td>0.9606</td>\n      <td>0.7006</td>\n      <td>0.9857</td>\n      <td>4.0</td>\n      <td>lupascu2016</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>no FoV</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>kumar2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>0.9432</td>\n      <td>0.7503</td>\n      <td>0.9717</td>\n      <td>4.0</td>\n      <td>ricci2007</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>FoV</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>True</td>\n      <td>False</td>\n      <td>FoV</td>\n      <td>FoV</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>rahmani2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>0.9521</td>\n      <td>0.7400</td>\n      <td>0.9726</td>\n      <td>4.0</td>\n      <td>rahmani2020</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>no FoV</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>atli2020</td>\n      <td>primary</td>\n      <td>2020.0</td>\n      <td>yes</td>\n      <td>0.9689</td>\n      <td>0.7987</td>\n      <td>0.9854</td>\n      <td>4.0</td>\n      <td>wang2015</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>outlier</td>\n      <td>outlier</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>narkthewan2019</td>\n      <td>primary</td>\n      <td>2019.0</td>\n      <td>yes</td>\n      <td>0.9617</td>\n      <td>0.6392</td>\n      <td>0.9920</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>no</td>\n      <td>...</td>\n      <td>outlier</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>True</td>\n      <td>no FoV</td>\n      <td>outlier</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows  33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "methods"
   ]
  }
 ]
}