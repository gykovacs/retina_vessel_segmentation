{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Extracting some the image statistics from the DRIVE database used in the study"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary packages\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFilter\n",
    "import os.path\n",
    "\n",
    "from config import drive_dir, image_stats_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the list of files\n",
    "files= glob.glob(os.path.join(drive_dir, '*', '*', '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training and test images\n",
    "training= [f for f in files if 'training' in f]\n",
    "test= [f for f in files if 'test' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting images, fov masks and manual segmentations\n",
    "\n",
    "training_img= [f for f in training if 'images' in f]\n",
    "training_mask= [f for f in training if 'mask' in f]\n",
    "training_manual= [f for f in training if 'manual' in f]\n",
    "\n",
    "test_img= [f for f in test if 'images' in f]\n",
    "test_mask= [f for f in test if 'mask' in f]\n",
    "test_manual1= [f for f in test if 'manual1' in f]\n",
    "test_manual2= [f for f in test if 'manual2' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting image statistics:\n",
    "# * number of positive and negative pixels for both the training and test images, with and without FoV\n",
    "# * computing the performance scores by treating the annotations of observer 1 as the ground truth and those of observer 2 as segmentations and vice versa\n",
    "\n",
    "img_stats= []\n",
    "\n",
    "for img in training_img:\n",
    "    # calculating basic statistics for the training images\n",
    "    identifier= img.split(os.sep)[-1].split('_')[0]\n",
    "    mask= [f for f in training_mask if identifier in f][0]\n",
    "    manual= [f for f in training_manual if identifier in f][0]\n",
    "\n",
    "    mask= np.array(Image.open(mask))\n",
    "    manual= np.array(Image.open(manual))\n",
    "\n",
    "    p_no_fov= np.sum(manual > 0)\n",
    "    n_no_fov= np.sum(manual == 0)\n",
    "    p_fov= np.sum(np.logical_and(manual > 0, mask > 0))\n",
    "    n_fov= np.sum(np.logical_and(manual == 0, mask > 0))\n",
    "    size_fov= np.sum(mask > 0)\n",
    "    n= np.prod(manual.shape)\n",
    "\n",
    "    img_stats.append([identifier, size_fov, p_fov, n_fov, True, 1, None, None, None, None, None, mask.shape[0], mask.shape[1], np.prod(mask.shape), False])\n",
    "    img_stats.append([identifier, n, p_no_fov, n_no_fov, False, 1, None, None, None, None, None, mask.shape[0], mask.shape[1], np.prod(mask.shape), False])\n",
    "\n",
    "for img in test_img:\n",
    "    # calculating basic statistics and performance scores for the test images\n",
    "    identifier= img.split(os.sep)[-1].split('_')[0]\n",
    "    mask= [f for f in test_mask if identifier in f][0]\n",
    "    manual1= [f for f in test_manual1 if identifier in f][0]\n",
    "    manual2= [f for f in test_manual2 if identifier in f][0]\n",
    "\n",
    "    mask= np.array(Image.open(mask))\n",
    "    manual1= np.array(Image.open(manual1))\n",
    "    manual2= np.array(Image.open(manual2))\n",
    "\n",
    "    p_no_fov= np.sum(manual1 > 0)\n",
    "    n_no_fov= np.sum(manual1 == 0)\n",
    "    p_fov= np.sum(np.logical_and(manual1 > 0, mask > 0))\n",
    "    n_fov= np.sum(np.logical_and(manual1 == 0, mask > 0))\n",
    "    size_fov= np.sum(mask > 0)\n",
    "    n= np.prod(manual1.shape)\n",
    "\n",
    "    # manual1 being the ground truth, treating manual2 as a segmentation, using FOV\n",
    "    tp= np.sum(np.logical_and(np.logical_and(manual1 > 0, manual2 > 0), mask > 0))\n",
    "    fp= np.sum(np.logical_and(np.logical_and(manual1 == 0, manual2 > 0), mask > 0))\n",
    "    tn= np.sum(np.logical_and(np.logical_and(manual1 == 0, manual2 == 0), mask > 0))\n",
    "    fn= np.sum(np.logical_and(np.logical_and(manual1 > 0, manual2 == 0), mask > 0))\n",
    "\n",
    "    img_stats.append([identifier, size_fov, p_fov, n_fov, True, 1, tp, fp, tn, fn, 1, mask.shape[0], mask.shape[1], np.prod(mask.shape), True])\n",
    "\n",
    "    # manual1 being the ground truth, treating manual2 as a segmentation, without FOV\n",
    "    tp= np.sum(np.logical_and(manual1 > 0, manual2 > 0))\n",
    "    fp= np.sum(np.logical_and(manual1 == 0, manual2 > 0))\n",
    "    tn= np.sum(np.logical_and(manual1 == 0, manual2 == 0))\n",
    "    fn= np.sum(np.logical_and(manual1 > 0, manual2 == 0))\n",
    "\n",
    "    img_stats.append([identifier, n, p_no_fov, n_no_fov, False, 1, tp, fp, tn, fn, 1, mask.shape[0], mask.shape[1], np.prod(mask.shape), True])\n",
    "\n",
    "    # manual2 being the ground truth, treating manual1 as a segmentation, using FOV\n",
    "    p_no_fov= np.sum(manual2 > 0)\n",
    "    n_no_fov= np.sum(manual2 == 0)\n",
    "    p_fov= np.sum(np.logical_and(manual2 > 0, mask > 0))\n",
    "    n_fov= np.sum(np.logical_and(manual2 == 0, mask > 0))\n",
    "    size_fov= np.sum(mask > 0)\n",
    "    n= np.prod(manual2.shape)\n",
    "\n",
    "    tp= np.sum(np.logical_and(np.logical_and(manual2 > 0, manual1 > 0), mask > 0))\n",
    "    fp= np.sum(np.logical_and(np.logical_and(manual2 == 0, manual1 > 0), mask > 0))\n",
    "    tn= np.sum(np.logical_and(np.logical_and(manual2 == 0, manual1 == 0), mask > 0))\n",
    "    fn= np.sum(np.logical_and(np.logical_and(manual2 > 0, manual1 == 0), mask > 0))\n",
    "\n",
    "    img_stats.append([identifier, size_fov, p_fov, n_fov, True, 2, tp, fp, tn, fn, 2, mask.shape[0], mask.shape[1], np.prod(mask.shape), True])\n",
    "\n",
    "    # manual2 being the ground truth, treating manual1 as a segmentation, without FOV\n",
    "    tp= np.sum(np.logical_and(manual2 > 0, manual1 > 0))\n",
    "    fp= np.sum(np.logical_and(manual2 == 0, manual1 > 0))\n",
    "    tn= np.sum(np.logical_and(manual2 == 0, manual1 == 0))\n",
    "    fn= np.sum(np.logical_and(manual2 > 0, manual1 == 0))\n",
    "\n",
    "    img_stats.append([identifier, n, p_no_fov, n_no_fov, False, 2, tp, fp, tn, fn, 2, mask.shape[0], mask.shape[1], np.prod(mask.shape), True])\n",
    "\n",
    "# constructing the image statistics dataframe\n",
    "img_stats= pd.DataFrame(img_stats, columns= ['id', 'n_all', 'p', 'n', 'fov', 'annotator', 'tp', 'fp', 'tn', 'fn', 'ground_truth', 'width', 'height', 'img_size', 'test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the image level accuracy, sensitivity and specificity scores\n",
    "img_stats['acc']= (img_stats['tp'] + img_stats['tn'])/(img_stats['n_all'])\n",
    "img_stats['sens']= (img_stats['tp'])/(img_stats['p'])\n",
    "img_stats['spec']= (img_stats['tn'])/(img_stats['n'])\n",
    "img_stats['dice']= (2*img_stats['tp'])/(2*img_stats['tp'] + img_stats['fp'] + img_stats['fn'])\n",
    "img_stats['dice_no_fp']= (2*img_stats['tp'])/(2*img_stats['tp'] + img_stats['fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     id   n_all      p       n    fov  annotator       tp      fp        tn  \\\n",
       "0    34  226542  32287  194255   True          1      NaN     NaN       NaN   \n",
       "1    34  329960  32287  297673  False          1      NaN     NaN       NaN   \n",
       "2    24  227726  38215  189511   True          1      NaN     NaN       NaN   \n",
       "3    24  329960  38229  291731  False          1      NaN     NaN       NaN   \n",
       "4    29  227309  27738  199571   True          1      NaN     NaN       NaN   \n",
       "..   ..     ...    ...     ...    ...        ...      ...     ...       ...   \n",
       "115  18  329960  30321  299639  False          2  22439.0  3705.0  295934.0   \n",
       "116  15  227394  23612  203782   True          1  18896.0  5720.0  198062.0   \n",
       "117  15  329960  23614  306346  False          1  18896.0  5720.0  300626.0   \n",
       "118  15  227394  24616  202778   True          2  18896.0  4716.0  198062.0   \n",
       "119  15  329960  24616  305344  False          2  18896.0  4718.0  300626.0   \n",
       "\n",
       "         fn  ground_truth  width  height  img_size   test       acc      sens  \\\n",
       "0       NaN           NaN    584     565    329960  False       NaN       NaN   \n",
       "1       NaN           NaN    584     565    329960  False       NaN       NaN   \n",
       "2       NaN           NaN    584     565    329960  False       NaN       NaN   \n",
       "3       NaN           NaN    584     565    329960  False       NaN       NaN   \n",
       "4       NaN           NaN    584     565    329960  False       NaN       NaN   \n",
       "..      ...           ...    ...     ...       ...    ...       ...       ...   \n",
       "115  7882.0           2.0    584     565    329960   True  0.964884  0.740048   \n",
       "116  4716.0           1.0    584     565    329960   True  0.954106  0.800271   \n",
       "117  4718.0           1.0    584     565    329960   True  0.968366  0.800203   \n",
       "118  5720.0           2.0    584     565    329960   True  0.954106  0.767631   \n",
       "119  5720.0           2.0    584     565    329960   True  0.968366  0.767631   \n",
       "\n",
       "         spec      dice  dice_no_fp  \n",
       "0         NaN       NaN         NaN  \n",
       "1         NaN       NaN         NaN  \n",
       "2         NaN       NaN         NaN  \n",
       "3         NaN       NaN         NaN  \n",
       "4         NaN       NaN         NaN  \n",
       "..        ...       ...         ...  \n",
       "115  0.987635  0.794793    0.850607  \n",
       "116  0.971931  0.783611    0.889056  \n",
       "117  0.981328  0.783579    0.889014  \n",
       "118  0.976743  0.783611    0.868542  \n",
       "119  0.984549  0.783579    0.868542  \n",
       "\n",
       "[120 rows x 20 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>n_all</th>\n      <th>p</th>\n      <th>n</th>\n      <th>fov</th>\n      <th>annotator</th>\n      <th>tp</th>\n      <th>fp</th>\n      <th>tn</th>\n      <th>fn</th>\n      <th>ground_truth</th>\n      <th>width</th>\n      <th>height</th>\n      <th>img_size</th>\n      <th>test</th>\n      <th>acc</th>\n      <th>sens</th>\n      <th>spec</th>\n      <th>dice</th>\n      <th>dice_no_fp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34</td>\n      <td>226542</td>\n      <td>32287</td>\n      <td>194255</td>\n      <td>True</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>34</td>\n      <td>329960</td>\n      <td>32287</td>\n      <td>297673</td>\n      <td>False</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24</td>\n      <td>227726</td>\n      <td>38215</td>\n      <td>189511</td>\n      <td>True</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>24</td>\n      <td>329960</td>\n      <td>38229</td>\n      <td>291731</td>\n      <td>False</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29</td>\n      <td>227309</td>\n      <td>27738</td>\n      <td>199571</td>\n      <td>True</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>18</td>\n      <td>329960</td>\n      <td>30321</td>\n      <td>299639</td>\n      <td>False</td>\n      <td>2</td>\n      <td>22439.0</td>\n      <td>3705.0</td>\n      <td>295934.0</td>\n      <td>7882.0</td>\n      <td>2.0</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>True</td>\n      <td>0.964884</td>\n      <td>0.740048</td>\n      <td>0.987635</td>\n      <td>0.794793</td>\n      <td>0.850607</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>15</td>\n      <td>227394</td>\n      <td>23612</td>\n      <td>203782</td>\n      <td>True</td>\n      <td>1</td>\n      <td>18896.0</td>\n      <td>5720.0</td>\n      <td>198062.0</td>\n      <td>4716.0</td>\n      <td>1.0</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>True</td>\n      <td>0.954106</td>\n      <td>0.800271</td>\n      <td>0.971931</td>\n      <td>0.783611</td>\n      <td>0.889056</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>15</td>\n      <td>329960</td>\n      <td>23614</td>\n      <td>306346</td>\n      <td>False</td>\n      <td>1</td>\n      <td>18896.0</td>\n      <td>5720.0</td>\n      <td>300626.0</td>\n      <td>4718.0</td>\n      <td>1.0</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>True</td>\n      <td>0.968366</td>\n      <td>0.800203</td>\n      <td>0.981328</td>\n      <td>0.783579</td>\n      <td>0.889014</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>15</td>\n      <td>227394</td>\n      <td>24616</td>\n      <td>202778</td>\n      <td>True</td>\n      <td>2</td>\n      <td>18896.0</td>\n      <td>4716.0</td>\n      <td>198062.0</td>\n      <td>5720.0</td>\n      <td>2.0</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>True</td>\n      <td>0.954106</td>\n      <td>0.767631</td>\n      <td>0.976743</td>\n      <td>0.783611</td>\n      <td>0.868542</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>15</td>\n      <td>329960</td>\n      <td>24616</td>\n      <td>305344</td>\n      <td>False</td>\n      <td>2</td>\n      <td>18896.0</td>\n      <td>4718.0</td>\n      <td>300626.0</td>\n      <td>5720.0</td>\n      <td>2.0</td>\n      <td>584</td>\n      <td>565</td>\n      <td>329960</td>\n      <td>True</td>\n      <td>0.968366</td>\n      <td>0.767631</td>\n      <td>0.984549</td>\n      <td>0.783579</td>\n      <td>0.868542</td>\n    </tr>\n  </tbody>\n</table>\n<p>120 rows Ã— 20 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "img_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the results into a csv file\n",
    "img_stats.to_csv(image_stats_file, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.31217460702307354"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# mean fov size\n",
    "entire_img_size= img_stats[img_stats['fov'] == False]['n_all'].reset_index(drop=True).astype(float)\n",
    "fov_size= img_stats[img_stats['fov'] == True]['n_all'].reset_index(drop=True).astype(float)\n",
    "np.mean((entire_img_size - fov_size)/entire_img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for test images with performance scores using annotation #1 as ground truth, with and without FoV\n",
    "img_stats_test= img_stats[(img_stats['test'] == True) & (img_stats['ground_truth'] == 1)]\n",
    "with_fov= img_stats_test[img_stats_test['fov'] == True].reset_index(drop=True)\n",
    "without_fov= img_stats_test[img_stats_test['fov'] == False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "p              28882.450000\n",
       "n             198024.700000\n",
       "acc                0.947283\n",
       "sens               0.776027\n",
       "spec               0.972495\n",
       "dice               0.788123\n",
       "dice_no_fp         0.872700\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# determining the mean scores treating the annotations of observer 2 as a segmentation under the FoV\n",
    "np.mean(with_fov[['p', 'n', 'acc', 'sens', 'spec', 'dice', 'dice_no_fp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "p             2679.699134\n",
       "n             3089.591674\n",
       "acc              0.004720\n",
       "sens             0.057926\n",
       "spec             0.008102\n",
       "dice             0.020045\n",
       "dice_no_fp       0.036558\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# determining the standard deviation of scores treating the annotations of observer 2 as a segmentation under the FoV\n",
    "np.std(with_fov[['p', 'n', 'acc', 'sens', 'spec', 'dice', 'dice_no_fp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "acc     0.963703\n",
       "sens    0.775673\n",
       "spec    0.981897\n",
       "dice    0.787928\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# determining the mean scores treating the annotations of observer 2 as a segmentation without the FoV\n",
    "np.mean(without_fov[['acc', 'sens', 'spec', 'dice']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# determining the maximum difference in the number of positives with and without FoV\n",
    "np.max(without_fov['p'].reset_index(drop=True) - with_fov['p'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.14608756243826987"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# determining the ratio of positives and negatives when FoV is used\n",
    "np.mean(with_fov['p']/with_fov['n'])"
   ]
  }
 ]
}